% ------------------------------------------------------------------------
% Senac Tex: Modelo de Trabalho Academico para o Centro Universitário
% Senac
% ------------------------------------------------------------------------

% ========================================================================
% CONFIGURAÇÃO DO DOCUMENTO
% ========================================================================


\documentclass[
	% -- opções da classe memoir --
	12pt,				% tamanho da fonte
	openright,			% capítulos começam em pág ímpar (insere página vazia caso preciso)
	oneside,			% para impressão em verso e anverso. Oposto a oneside
	a4paper,			% tamanho do papel. 
	% -- opções da classe abntex2 --
	%chapter=TITLE,		% títulos de capítulos convertidos em letras maiúsculas
	%section=TITLE,		% títulos de seções convertidos em letras maiúsculas
	%subsection=TITLE,	% títulos de subseções convertidos em letras maiúsculas
	%subsubsection=TITLE,% títulos de subsubseções convertidos em letras maiúsculas
	% -- opções do pacote babel --
	english,			% idioma adicional para hifenização
	brazil				% o último idioma é o principal do documento
	]{abntex2}

% ---
% Pacotes básicos 
% ---
\usepackage{lmodern}			% Usa a fonte Latin Modern			
\usepackage[T1]{fontenc}		% Selecao de codigos de fonte.
\usepackage[utf8]{inputenc}		% Codificacao do documento (conversão automática dos acentos)
\usepackage{lastpage}			% Usado pela Ficha catalográfica
\usepackage{indentfirst}		% Indenta o primeiro parágrafo de cada seção.
\usepackage{color}				% Controle das cores
\usepackage{graphicx}			% Inclusão de gráficos
\usepackage{microtype} 			% para melhorias de justificação
\usepackage{listings}
\usepackage{indentfirst}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[top=3cm, bottom=2cm, left=3cm, right=2cm]{geometry}
% Tabularx and ragged2e are required for wide tables using X columns
\usepackage{tabularx}
\usepackage{ragged2e}

% Define \textus used in the document (formatting for parameter names/code-like text)
\newcommand{\textus}[1]{\texttt{#1}}

% ---
% Pacotes de citações
% ---
\usepackage[brazilian,hyperpageref]{backref}	 % Paginas com as citações na bibl
\usepackage[alf]{abntex2cite}	% Citações padrão ABNT

% CONFIGURAÇÕES DE PACOTES

% Configurações do pacote backref
% Usado sem a opção hyperpageref de backref
\renewcommand{\backrefpagesname}{Citado na(s) página(s):~}
% Texto padrão antes do número das páginas
\renewcommand{\backref}{}
% Define os textos da citação
\renewcommand*{\backrefalt}[4]{
	\ifcase #1 %
		Nenhuma citação no texto.%
	\or
		Citado na página #2.%
	\else
		Citado #1 vezes nas páginas #2.%
	\fi}%

% Informações de dados para CAPA e FOLHA DE ROSTO
\titulo{Previsão de Resultados da NBA com CatBoost: Uma Análise Preditiva de Jogos}
\autor{Erik Pires Zaina, Lucas Gonçalo de Morais, Murilo dos Santos Sena}
\local{São Paulo - Brasil}
\data{2025}
\orientador{Alessandro Ranulfo Nery}
%\coorientador{Nome do Coorientador}
\instituicao{
  Centro Universitário Senac - Santo Amaro
  \par
  Bacharelado em Ciência da Computação
}
\tipotrabalho{Trabalho de Conclusão de Curso}
% O preambulo deve conter o tipo do trabalho, o objetivo, 
% o nome da instituição e a área de concentração 
\preambulo{Monografia apresentada na disciplina Trabalho de Conclusão de Curso, como parte dos requisitos para obtenção do título de Bacharel em Ciência da Computação.}

% Configurações de aparência do PDF final

% alterando o aspecto da cor azul
\definecolor{blue}{RGB}{41,5,195}

% informações do PDF
\makeatletter
\hypersetup{
     	%pagebackref=true,
		pdftitle={\@title}, 
		pdfauthor={\@author},
    	pdfsubject={\imprimirpreambulo},
	    pdfcreator={LaTeX with abnTeX2},
		pdfkeywords={abnt}{latex}{abntex}{abntex2}{trabalho acadêmico}, 
		colorlinks=true,       		% false: boxed links; true: colored links
    	linkcolor=black,          	% color of internal links
    	citecolor=black,        		% color of links to bibliography
    	filecolor=magenta,      		% color of file links
		urlcolor=black,
		bookmarksdepth=4
}
\makeatother

% Espaçamentos entre linhas e parágrafos 

% O tamanho do parágrafo é dado por:
\setlength{\parindent}{1.25cm}

% Controle do espaçamento entre um parágrafo e outro:
\setlength{\parskip}{0.2cm}

\SingleSpacing
\makeatletter
\let\@fnsymbol\@arabic
\makeatother

% compila o indice
\makeindex

\begin{document}

% Retira espaço extra obsoleto entre as frases.
\frenchspacing

% ========================================================================
% CAPA
% ========================================================================
\imprimircapa

% ========================================================================
% FOLHA DE ROSTO
% ========================================================================
\imprimirfolhaderosto

% ========================================================================
% LISTA DE ILISTRAÇÕES
% ========================================================================
\pdfbookmark[0]{\listfigurename}{lof}
\listoffigures*
\cleardoublepage

% ========================================================================
% LISTA DE TABELAS
% ========================================================================
\pdfbookmark[0]{\listtablename}{lot}
\listoftables*
\cleardoublepage

% ========================================================================
% LISTA DE ABREVIATURAS E SIGLAS
% ========================================================================
\begin{siglas}
  \item[AI] Artificial Intelligence (Inteligência Artificial)
  \item[API] Application Programming Interface (Interface de Programação de Aplicações)
  \item[BPM] Box Plus/Minus
  \item[EQM] Erro Quadrático Médio
  \item[IA] Inteligência Artificial
  \item[JSON] JavaScript Object Notation
  \item[MDP] Markov Decision Process (Processo de Decisão de Markov)
  \item[ML] Machine Learning (Aprendizado de Máquina)
  \item[NBA] National Basketball Association
  \item[OTW] Optimal Time Window (Janela Temporal Ótima)
  \item[PER] Player Efficiency Rating
  \item[SHAP] Shapley Additive Explanations
  \item[SVM] Support Vector Machine (Máquina de Vetores de Suporte)
  \item[VORP] Value Over Replacement Player
  \item[XGBoost] Extreme Gradient Boosting
\end{siglas}



% ========================================================================
% SUMÁRIO
% ========================================================================
\pdfbookmark[0]{\contentsname}{toc}
\tableofcontents*
\cleardoublepage

\textual
% ========================================================================
% INTRODUÇÃO
% ========================================================================
\chapter{Introdução}


\section{Contexto}

O esporte profissional mudou muito na última década. A tomada de decisão deixou de depender quase só de intuição e avaliação subjetiva para adotar uma abordagem quantitativa baseada em dados. Esse movimento consolidou a análise esportiva como área que usa algoritmos, aprendizado de máquina e modelagem preditiva para entender o desempenho. A \textit{National Basketball Association} (NBA) é historicamente rica em dados, o recente avanço está na maior granularidade e acessibilidade, que ampliaram o uso de métodos quantitativos \citeonline{obi2024}.


A avaliação de desempenho também mudou. Em vez de métricas isoladas e regras fixas, ganham espaço modelos adaptativos que aprendem padrões a partir de grandes históricos de jogos, treinos e dados físicos. Com isso, melhora-se a capacidade de prever resultados e de generalizar para novos cenários \citeonline{Sarlis}.

Os efeitos são práticos. Um estudo com 12 temporadas da NBA encontrou correlação positiva e estatisticamente significativa entre o investimento em departamentos de análise e o número de vitórias. O resultado permaneceu mesmo controlando por fatores como folha salarial, experiência e química do elenco, estabilidade da comissão técnica e lesões. O tamanho e a qualificação da equipe de análise apareceram como preditores consistentes de sucesso em quadra \citeonline{henryWang}.

No entanto, muitos modelos preditivos ainda se baseiam em estatísticas agregadas por equipe. Essa abordagem, embora útil, apresenta uma limitação fundamental: a NBA é uma liga impulsionada por jogadores. O desempenho de uma equipe pode variar significativamente em função de trocas, lesões ou simplesmente da rotação de atletas em partidas específicas \citeonline{kovacs2024}. Modelos que consideram apenas dados coletivos são, portanto, mais frágeis diante dessa volatilidade e incapazes de capturar as interações e contribuições individuais que frequentemente determinam o resultado dos jogos. Diante dessa lacuna, este trabalho propõe investigar se a incorporação de \textit{features} em nível de jogador, combinadas às métricas tradicionais de equipe, pode gerar um modelo mais preciso e mais resiliente à alta variabilidade característica da liga.

A escolha do algoritmo é de grande importância para lidar com a complexidade dos dados esportivos, que incluem uma mistura de variáveis numéricas e categóricas (como time da casa vs. visitante, conferência, etc.). Para este fim, foi selecionado o CatBoost  \textit{(Categorical Boosting)}, um algoritmo de gradient boosting desenvolvido pela Yandex \citeonline{Prokhorenkova2018}. Sua principal vantagem é o tratamento nativo de características categóricas, eliminando a necessidade de pré-processamentos manuais que podem levar à perda de informação \citeonline{Prokhorenkova2018}. Além disso, o CatBoost implementa uma técnica chamada Ordered Boosting, projetada para reduzir o sobreajuste \textit{(overfitting)} e evitar um tipo de vazamento de dados \textit{(target leakage)} comum em outras implementações de boosting, resultando em modelos mais generalizáveis.

Um dos maiores desafios na aplicação de aprendizado de máquina é o "dilema da caixa-preta" \textit{(black box dilemma)}. Modelos complexos como os de gradient boosting, apesar de sua alta precisão, são frequentemente opacos, dificultando a interpretação de suas previsões por parte dos tomadores de decisões \citeonline{OuYang2025}. Para que um modelo seja verdadeiramente útil, ele não deve apenas prever, mas também explicar o "porquê" por trás de suas decisões. 

\section{Objetivos}

O estudo aqui descrito pretende desenvolver um modelo baseado no algoritmo de gradient boosting (CatBoost), visando propor um método nele baseado, para a previsão de resultados de partidas da NBA. Neste caso, a própria forma recente das equipes e as estatísticas avançadas dos jogadores são utilizadas para verificar a probabilidade de vitória de cada time.

A abordagem proposta busca definir de maneira mais fiel o momento (ou "forma") atual de uma equipe, utilizando e pesos dinâmicas, permitindo assim descobrir com mais precisão os padrões que levam à vitória.

\subsection{Objetivo Específico}
\begin{itemize}
    \item Criar um pipeline de engenharia de features para calcular métricas dinâmicas e adaptativas.
    \item Criar um módulo para integrar e agregar estatísticas de desempenho individual de jogadores.
    \item Treinar e validar o modelo usando um método de validação temporal cruzada com embargo.
    \item Implementar um algoritmo de explicabilidade (SHAP) para analisar o impacto de cada feature nas previsões individuais.
    \item Avaliar o desempenho e a calibração do modelo em dados de teste temporalmente isolados.
\end{itemize}



% ========================================================================
% REVISÃO BIBLIOGRÁFICA
% ========================================================================
\chapter{Revisão Bibliográfica}

Este capítulo apresenta os principais conceitos, métodos e estudos anteriores relacionados à modelagem computacional aplicada à previsão de resultados na NBA. Serão abordados os algoritmos de machine learning utilizados em predições esportivas, a importância da interpretabilidade, o contexto específico da NBA enquanto domínio da aplicação, além de técnicas como CatBoost, SHAP e a Janela Temporal Ótima (OTW).

\section{National Basketball Association (NBA)}

A National Basketball Association (NBA) é uma das principais ligas de basquete profissional do mundo, sediada na América do Norte e composta por 30 equipes divididas entre as conferêrencias Leste e Oeste \cite{BritannicaNBA}. Fundada oficialmente em 1949, a National Basketball Association (NBA) surgiu da fusão entre duas organizações rivais: a Basketball Association of America (fundada em 1946) e a National Basketball League (fundada em 1937). A NBA é reconhecida por reunir atletas de destaque internacional e desempenhar papel central no cenário global do basquete profissional \cite{BritannicaNBA}. Al\'em de seu apelo esportivo e de entretenimento, a NBA distingue-se pela abund\^ancia de dados estat\'isticos coletados a cada partida e temporada. Cada jogo gera uma rica folha estat\'istica (\textit{box score}) com dezenas de indicadores (pontos, rebotes, assist\^encias, etc.), al\'em de estat\'isticas agregadas por temporada. Ao longo das \'ultimas d\'ecadas, esse volume de dados impulsionou o surgimento de an\'alises quantitativas e m\'etricas avançadas no basquete, muitas das quais influenciaram tanto a comunidade acad\^emica quanto as decis\~oes gerenciais de times profissionais \cite{Oliver2004,Kubatko2007}


\subsection{Métricas Avançadas no Basquete}

Métricas avançadas são medidas estatísticas elaboradas com o objetivo de avaliar de forma mais acurada o desempenho de jogadores e equipes, indo além dos números tradicionais. Diversos pesquisadores e analistas pioneiros desenvolveram tais métricas. John Hollinger, por exemplo, introduziu o Player Efficiency Rating (PER), que combina os principais dados de box score de um jogador como pontos, rebotes, assistências, roubos, tocos e desperdícios de posse em um único índice de eficiência por minuto em quadra \citeonline{Hollinger2005}. O PER é padronizado para que a média da liga seja sempre 15, valores acima ou abaixo dessa média indicam o quão acima ou abaixo da média é a performance estatística do atleta. Os detalhes do cálculo, incluindo ajustes por ritmo de jogo (pace), são disponibilizados por plataformas especializadas como o \citeonline{BasketballRefPER}. Embora amplamente utilizado, o PER é criticado por não capturar aspectos defensivos mais sutis ou contribuições táticas intangíveis.

Outra classe importante são as métricas baseadas em \textit{plus/minus}, que avaliam o impacto de um jogador no placar enquanto ele está em quadra. O chamado \textit{plus/minus} bruto registra a diferença de pontos do placar com o jogador em ação já o \textit{Box Plus/Minus} (BPM) é uma versão avançada que estima, a partir das estatísticas individuais de \textit{box score}, quantos pontos por 100 posses de bola um jogador adiciona (ou subtrai) ao placar de seu time em relação a um jogador médio \cite{Myers2020}. O BPM leva em conta fatores como eficiência ofensiva e defensiva do time quando o jogador está em quadra, tentando isolar a contribuição individual do atleta \cite{Myers2020}. Embora introdutoriamente descrito em trabalhos como o de Kubatko et al. (2007), que discutem métricas de \textit{plus/minus} e suas limitações, o BPM em si foi refinado posteriormente dentro da comunidade de analistas de basquete\cite{Kubatko2007}.


\begin{figure}[H]
\centering
\caption{Distribuição dos valores de BPM 2.0 entre 1974 e 2019.}

\includegraphics[width=8cm]{figuras/plusminus (1).png}
\legend{Fonte: \url{https://www.basketball-reference.com/about/bpm2.html}}
\label{fig:bpm_hist}
\end{figure}



\section{Inteligência Artificial}

A Inteligência Artificial (IA) é o campo da computação dedicado ao desenvolvimento de sistemas capazes de realizar tarefas que normalmente requereriam inteligência humana, como reconhecimento de padrões e tomada de decisão. Desde os primórdios, nos anos 1950, busca-se criar agentes artificiais que percebam o ambiente e ajam de forma autônoma para atingir objetivos estabelecidos\cite{Russell2010}.
\subsection{Aprendizado de Máquina}

O Aprendizado de Máquina (ML), uma das principais subáreas da IA, desenvolve algoritmos que permitem ao computador aprender padrões ou comportamentos a partir de dados e melhorar seu desempenho em tarefas específicas. Uma definição clássica descreve que um algoritmo de ML explora dados de treinamento para induzir um modelo capaz de fazer predições ou decisões sem ser explicitamente programado para cada caso \cite{mitchell1997}.

Os métodos de ML costumam ser categorizados em aprendizado supervisionado, não supervisionado e por reforço, sendo este trabalho focado em técnicas supervisionadas de classificação. Nos últimos anos, redes neurais profundas (aprendizado profundo) alcançaram avanços notáveis em tarefas complexas como visão computacional e jogos estratégicos\cite{goodfellow2016}, contudo, esses modelos tipicamente requerem grandes volumes de dados e alto poder computacional. Para dados estruturados tabulares, técnicas de \textit{ensemble} baseadas em árvores de decisão, como o \textit{boosting}, têm se destacado pela alta eficácia preditiva.

%%Realmente, acho que vai ter importância explicar o ensamble 

A técnica de \textit{boosting}, introduzida por Freund e Schapire\cite{Freund1997} e posteriormente generalizada por Friedman\cite{Friedman2001}, combina múltiplos modelos fracos de forma sequencial para formar um modelo final mais sólido. Implementações modernas, como o XGBoost\cite{Chen2016} e o CatBoost\cite{Prokhorenkova2018}, incorporam diversas otimizações e obtêm desempenho de ponta em muitos cenários de classificação e regressão.

%%Aqui eu acho que esse último paragráfo é melhor que o primeiro paragráfo dos algoritmos de boosting

\subsection{Aprendizado Supervisionado}

No aprendizado supervisionado, o algoritmo recebe um conjunto de exemplos de treinamento compostos por pares de entrada e saída esperada (rótulo ou valor) \cite{mitchell1997}. O objetivo é aprender uma função ou modelo que mapeie as entradas para as saídas corretas, de forma geral para novos dados não vistos. Tipicamente, problemas supervisionados subdividem-se em classificação (quando a saída é uma classe ou categoria) e regressão (quando a saída é um valor numérico contínuo) \cite{Alpaydin2010}. Exemplos de algoritmos supervisionados incluem regressão logística, máquinas de vetores de suporte (SVM), árvores de decisão e redes neurais artificiais \cite{mitchell1997,Alpaydin2010}. 

Esses algoritmos ajustam seus parâmetros internos para minimizar um erro de previsão em relação aos rótulos conhecidos do conjunto de treino. Quando bem-sucedido, o modelo resultante consegue generalizar o aprendizado para realizar previsões acuradas em novos dados \cite{mitchell1997}. Nos últimos anos, métodos de aprendizado profundo (\textit{deep learning}, redes neurais com muitas camadas) tornaram-se proeminentes dentro do paradigma supervisionado, alcançando avanços significativos em tarefas como reconhecimento de imagens e jogos estratégicos \cite{goodfellow2016}.
 Embora redes profundas exijam grandes volumes de dados e poder computacional, elas demonstram o potencial do aprendizado supervisionado quando as condições de treinamento são favoráveis \cite{goodfellow2016}.

\subsection{Algoritmos de Boosting}\label{subsec:boosting-geral} O boosting é uma técnica de aprendizado de máquina que combina vários modelos simples (``fracos'') de forma sequencial para formar um modelo final mais forte e preciso\cite{AWSBoosting}. 

Em cada iteração do processo de boosting, um novo modelo é treinado para corrigir os erros do conjunto de modelos anteriores, focando especialmente nas instâncias que foram preditas incorretamente nas etapas precedentes. Diferentemente do \emph{bagging} (onde modelos são treinados em paralelo em subconjuntos aleatórios dos dados), no boosting os modelos são ajustados em sequência adaptativa, de modo que cada modelo adicional concentra-se nos erros do anterior. Essa estratégia iterativa tende a reduzir o viés do modelo e, quando bem regulamentada, produz modelos de alta acurácia em tarefas de classificação e regressão\cite{AWSBoosting}. Um dos primeiros e mais influentes algoritmos dessa família é o AdaBoost (\emph{Adaptive Boosting}), proposto por Freund e Schapire na década de 1990 \cite{Freund1997}.

O AdaBoost foi concebido para problemas de classificação binária e mostrou empiricamente como combinar múltiplos classificadores fracos (por exemplo, árvores de decisão rasas ou \emph{stumps}) pode gerar um classificador forte com desempenho significativamente melhor \cite{Freund1997}. Em cada iteração do AdaBoost, os pesos associados a cada instância de treinamento são ajustados: exemplos que foram classificados incorretamente pelo modelo anterior têm seus pesos aumentados, enquanto exemplos classificados corretamente têm seus pesos reduzidos. Em seguida, um novo classificador fraco é treinado com base nesses pesos ajustados, enfatizando os exemplos difíceis. Cada classificador recebe uma ponderação $\alpha_m$ proporcional à sua performance (tipicamente calculada como uma função do erro de classificação), e a predição final do ensemble é obtida por uma votação ponderada desses classificadores \cite{Freund1997}. Do ponto de vista teórico, demonstra-se que o AdaBoost minimiza aproximadamente uma função de perda exponencial, o que ajuda a explicar seu sucesso em reduzir erros de generalização em diversas aplicações \cite{Schapire2012}. Aplicações típicas do AdaBoost incluem tarefas de classificação em visãocomputacional (por exemplo, detecção de faces) e outras áreas onde a interpretabilidade e a simplicidade dos classificadores fracos são vantajosas, embora hoje existam variantes mais robustas para dados complexos. 

Outro avanço fundamental foi a introdução do Gradient Boosting (boosting por gradiente), generalizado por Friedman \cite{Friedman2001}. Enquanto o AdaBoost ajusta iterativamente os modelos dando ênfase a erros de classificação, o Gradient Boosting reformula o problema de boosting como a otimização de uma função de perda arbitrária por meio de descida de gradiente em espaço de funções \cite{Friedman2001}. Nessa abordagem, em cada etapa $m$ ajusta-se um novo modelo base $h_m(x)$ para aproximar o gradiente negativo da função de perda (os esíduos) do modelo atual em relação aos dados de treinamento. Em outras palavras, o modelo sequencialmente tenta corrigir os resíduos (erros) do modelo conjunto anterior. Esse framework é bastante flexível: permite usar diferentes funções de perda (ex.: erro quadrático para regressão, deviação binária para classificação) e diferentes modelos base (embora sejam comumente utilizadas árvores de decisão CART de média profundidade como aprendizes fracos).

O Gradient Boosting provou ser altamente eficaz em uma variedade de domínios, pois combina a capacidade preditiva de modelos de alta variância (como árvores de decisão) com a redução de viés proporcionada pelo esquema de boosting. Ele rapidamente se tornou uma das técnicas de referência para dados tabulares, exibindo desempenho superior em muitas tarefas de classificação e regressão onde modelos lineares ou até redes neurais não capturam tão bem interações complexas entre variáveis\cite{McElfresh2024}.

Com o crescente uso do boosting em aplicações do mundo real, surgiram melhorias práticas no algoritmo de Friedman. Uma das mais proeminentes é o XGBoost (\emph{eXtreme Gradient Boosting}), proposto por Tianqi Chen \cite{Chen2016}. O XGBoost é essencialmente uma implementação otimizada do Gradient Boosting que incorpora diversas inovações para torná-lo mais rápido, escalável e ainda mais preciso. Dentre as contribuições técnicas do XGBoost estão: (i) a utilização de uma formulação de segunda ordem para a otimização o algoritmo calcula não apenas os gradientes primeiro-ordem, mas também o Hessiano (gradientes de segunda ordem) da função de perda para orientar o crescimento das árvores, o que acelera a convergência e pode melhorar a qualidade dos \emph{splits}\cite{Chen2016}, (ii) a introdução de um termo de regularização explícito na função objetivo, penalizando a complexidade das árvores (por exemplo, número de folhas e magnitude dos pesos nas folhas) para evitar sobreajuste \cite{Chen2016}; (iii) otimizações de computação, como processamento em paralelo dos nós da árvore, compressão de dados em memória e tratamento eficiente de valores ausentes e atributos esparsos. 

%Sinceramente, pensando em remover a parte matemática do XGBoost, já que não é nosso foco,

% Em termos simples, a função objetivo otimizada pelo XGBoost pode ser escrita como: 

% \begin{equation}
% L(\Theta) = \sum_{i} \ell(y_i, \hat{y}_i) + \sum_{k} \Omega(f_k)
% \end{equation}

% 
% Onde $\ell$ é a perda (por exemplo, erro quadrático, logística, etc.) e $\Omega(f_k)$ é o termo de regularização para a $k$-ésima árvore do ensemble \cite{Chen2016}. Essa regularização orienta o algoritmo a selecionar divisões que equilibrem bem a redução do erro de treinamento com a simplicidade do modelo. Graças a essas melhorias, o XGBoost alcançou enorme popularidade na comunidade de ciência de dados. Para se ter uma ideia, entre 29 soluções vencedoras de competições no site Kaggle em 2015, 17 utilizaram o XGBoost em seus modelos (sendo que 8 dessas soluções usaram o XGBoost como único modelo final), evidenciando seu desempenho competitivo em problemas do mundo real \cite{Chen2016}. O XGBoost é amplamente empregado em aplicações industriais e acadêmicas que envolvem dados estruturados, incluindo detecção de fraudes, pontuação de crédito, previsão de demanda e diversas outras tarefas de classificação e regressão. Sua eficácia é particularmente destacada em conjuntos de dados de tamanho médio, onde modelos baseados em árvores, como o XGBoost, frequentemente superam redes neurais, especialmente quando as características possuem relações complexas que árvores podem capturar eficazmente.\cite{Hajek2022, Xia2023, Grinsztajn2022, ShwartzZiv2021}.



\begin{figure}[htb]
    \centering
        \caption{Funcionamento do boosting como técnica de aprendizado de máquina baseada em múltiplos classificadores sequenciais.}
    \includegraphics[width=0.9\textwidth]{figuras/Texto do seu parágrafo (1) (1).png}
    \legend{Fonte: \url{https://commons.wikimedia.org/wiki/File:Ensemble_Boosting.svg}}
    \label{fig:boosting}
\end{figure}

\subsubsection{CatBoost}\label{subsec:catboost} O CatBoost (do inglês \emph{Category Boosting}) é um algoritmo mais recente de boosting por gradiente, desenvolvido pela equipe da Yandex, que se destaca por oferecer melhorias técnicas específicas em relação a implementações anteriores como o XGBoost e outros \cite{Prokhorenkova2018}.

Assim como estes, o CatBoost constrói um ensemble de árvores de decisão de forma sequencial para minimizar uma função de perda, porém, ele introduz técnicas que visam resolver problemas particulares do boosting tradicional, especialmente no tratamento de variáveis categóricas e na redução de vieses durante o treinamento. Essas inovações permitem ao CatBoost obter desempenho semelhante ou superior aos demais métodos de boosting em muitos cenários, além de facilitar seu uso em problemas com dados heterogêneos \cite{Prokhorenkova2018}.

Matematicamente, o CatBoost busca minimizar a função de perda esperada
\[
L(F) = \mathbb{E}_{(x,y)} \left[ \ell(y, F(x)) \right],
\]
onde $F:\mathbb{R}^m \to \mathbb{R}$ é o modelo preditor, $\ell$ é uma função de perda convexa e suave, e $(x,y)$ são os dados de entrada e alvo, respectivamente. Em cada iteração $t$, o modelo é atualizado adicionando uma árvore $h_t$ que aproxima o gradiente negativo da perda:
\[
F^{t}(x) = F^{t-1}(x) + \alpha h_t(x),
\]
com $\alpha$ sendo a taxa de aprendizado. A árvore $h_t$ é obtida ao resolver
\[
h_t = \arg\min_{h \in \mathcal{H}} \mathbb{E}_{(x,y)} \left[ \left(-g_t(x,y) - h(x)\right)^2 \right],
\]
Onde:
\[
g_t(x,y) = \left. \frac{\partial \ell(y, s)}{\partial s} \right|_{s=F^{t-1}(x)}
\]
é o gradiente da função de perda em relação à predição atual.

Uma das principais vantagens do CatBoost é o tratamento nativo de variáveis categóricas. Diferentemente do XGBoost e da maioria dos algoritmos de árvore, que exigem converter variáveis categóricas em representações numéricas (por exemplo, via codificação one-hot, label encoding ou embeddings fornecidos pelo usuário), o CatBoost lida internamente com atributos categóricos de forma eficiente \cite{Prokhorenkova2018}. Ele emprega uma técnica de \emph{target encoding} especial chamada de estatísticas ordenadas (\emph{ordered target statistics}), na qual os valores categóricos são transformados com base nas estatísticas de resposta (média ou likelihood do alvo) calculadas a partir dos dados de treinamento sem introduzir vazamento de informação do alvo (target leakage) \cite{Prokhorenkova2018}.

Em termos práticos, para cada exemplo $k$, o valor codificado $\hat{x}_{ik}$ para a variável categórica $i$ é calculado como

\[
\hat{x}_{ik} = \frac{\sum_{j:\sigma(j) < \sigma(k)} \mathbf{1}\{x_{ij} = x_{ik}\} y_j + a p}{\sum_{j:\sigma(j) < \sigma(k)} \mathbf{1}\{x_{ij} = x_{ik}\}  + a},
\]
Onde:
$\sigma$ é uma permutação aleatória dos índices das amostras, usada para garantir que apenas exemplos "anteriores" sejam considerados e evitar o vazamento de informação futura,
 $a > 0$ é um parâmetro de suavização que evita divisão por zero e controla o peso da constante $p$,
 $p$ é uma constante, tipicamente a média global do alvo,
 $\mathbf{1}\{\cdot\}$ é a função indicadora, que vale 1 se a condição é verdadeira e 0 caso contrário.

Essa abordagem se traduz no seguinte processo: o CatBoost percorre o conjunto de treinamento em diferentes permutações aleatórias e, para cada categoria, calcula gradualmente a média do alvo considerando apenas observações anteriores na ordem percorrida, junto com um termo de suavização bayesiana. Dessa forma, cada exemplo nunca contribui para a codificação de si mesmo, evitando viés. O resultado final é uma representação numérica de cada categoria que reflete a tendência de seu valor de acordo com os dados já vistos, minimizando overfitting e preservando a ordem temporal durante o treinamento \cite{Prokhorenkova2018}.

Em resumo, o CatBoost automatiza o manejo de dados categóricos, poupando trabalho de pré-processamento e frequentemente resultando em modelos mais acurados quando há muitas variáveis não numéricas. Outra inovação introduzida pelo CatBoost é o chamado \emph{ordered boosting} (boosting ordenado). No \emph{boosting} convencional (como Gradient Boosting e XGBoost), ao treinar o $m$-ésimo modelo do ensemble, utiliza-se todo o conjunto de treinamento atual (com as respostas reais) para calcular os resíduos ou gradientes inclusive para as próprias instâncias que esse modelo $m$ irá ajustar. Isso pode levar a um leve vazamento de informação, pois a etapa $m$ “vê” o valor real que deveria prever, ainda que como parte do cálculo do resíduo. O CatBoost resolve esse problema treinando cada nova árvore de decisão em um modo restrito: ele cria divisões ordenadas do dataset (novamente usando permutações aleatórias) e garante que, para calcular os resíduos e decidir os melhores \emph{splits} de uma nova árvore, sejam utilizadas apenas estatísticas obtidas de instâncias que já foram predizidas em etapas anteriores (ou que estão em outras partições), evitando que uma árvore em treinamento “se veja no espelho” \cite{Prokhorenkova2018}.

Além disso, o CatBoost adota árvores de decisão simétricas (também chamadas \emph{oblivious trees}) em sua construção do ensemble \cite{Prokhorenkova2018}. Diferentemente das árvores de decisão tradicionais, em que cada nó pode dividir por um critério diferente gerando estruturas irregulares, as árvores simétricas impõem que, em cada nível da árvore, todas as divisões ocorram pela mesma variável. Em outras palavras, a estrutura da árvore é balanceada e predefinida: primeiro todos os nós dividem pela variável $X$, depois todos os nós resultantes dividem pela variável $Y$, e assim por diante, independentemente de qual caminho na árvore está sendo considerado. Assim, as árvores simétricas contribuem para que o CatBoost mantenha desempenho em termos de velocidade e também reduzam a complexidade do modelo, o que pode ser vantajoso em dados com alto ruído ou altamente desequilibrados. Graças a esse conjunto de aprimoramentos, o CatBoost apresenta um desempenho vantajoso em comparação a demais  métodos de boosting. Os desenvolvedores do CatBoost reportaram que a combinação das técnicas de \emph{ordered boosting} e codificação eficiente de variáveis categóricas levou o algoritmo a superar implementações públicas existentes (como XGBoost e LightGBM) em termos de qualidade preditiva em uma variedade de conjuntos de dados benchmark \cite{Prokhorenkova2018}. Em particular, em tarefas com muitas variáveis categóricas ou com classes desbalanceadas, o CatBoost tende a se destacar: a abordagem livre de vazamentos evita favorecer indevidamente a classe majoritária durante o treinamento, e o algoritmo permite ajustar facilmente pesos para classes minoritárias se necessário, resultando em melhor equilíbrio entre desempenho e generalização. Em cenários gerais, mesmo sem ajustes específicos, o CatBoost frequentemente alcança acurácia igual ou superior à de seus concorrentes, necessitando menos engenharia de atributos por parte do usuário \cite{Prokhorenkova2018}. Além disso, seu desempenho com dados ruidosos e heterogêneos o torna atrativo em aplicações do mundo real. 


\begin{figure}[H]
    \centering
    \caption{Fluxo do algoritmo CatBoost baseado em Gradiente Boosting. O modelo é treinado com subconjuntos amostrados via bootstrap, com atualização sequencial de pesos e preditores.}
    \includegraphics[width=0.9\textwidth]{figuras/Dataset (1).png}
    \legend{Fonte: Adaptado de \citeonline{zeng2023}. }
    \label{fig:catboost}
\end{figure}



\subsection{Métricas de Avaliação}
A avaliação de modelos preditivos não deve se resumir a um único indicador. Neste trabalho, consideram-se três dimensões complementares: desempenho, discriminação e calibração. Desempenho mede o quanto o modelo acerta as classes. Discriminação avalia se o modelo consegue ordenar corretamente vencedores e perdedores ao atribuir probabilidades. Calibração verifica se as probabilidades previstas estão próximas das frequências observadas (por exemplo, \textit{Brier score} e curvas de calibração). Uma análise completa deve integrar essas três dimensões, ignorar qualquer uma delas pode levar a conclusões incompletas ou enganosas sobre a qualidade real do modelo \cite{jiang2020, giskard_calibration}

\subsubsection{Métricas de Desempenho de Classificação}
As métricas de desempenho de classificação são utilizadas para avaliar a eficácia do modelo em acertar a classe correta, medindo diretamente a frequência e o tipo de erros cometidos nas previsões finais.

\subsubsection{A Matriz de Confusão}
A Matriz de Confusão, também conhecida como matriz de erro, é uma tabela $N \times N$ que serve como base para a visualização e cálculo da performance de um classificador \cite{baheti_classification_metrics}. Para o problema binário de prever o resultado de um jogo da NBA (e.g., a equipe da casa vence), a matriz 2x2 compara os valores previstos pelo modelo com os valores reais \textit{(ground truth)} \cite{ibm_confusion_matrix}. A sua estrutura permite uma análise detalhada dos tipos de erros cometidos, fornecendo uma visão muito mais granular do que uma única métrica agregada pode oferecer.
Os seus componentes fundamentais são:
\begin{itemize}
    \item Verdadeiros Positivos \textit{(TP - True Positives)}: O modelo prevê corretamente que a equipe da casa vence, e a equipe da casa de facto vence.
    \item Verdadeiros Negativos \textit{(TN - True Negatives)}: O modelo prevê corretamente que a equipe da casa perde (ou seja, a equipe visitante vence), e a equipe da casa de facto perde.
    \item Falsos Positivos \textit{(FP - False Positives)}: O modelo prevê que a equipe da casa vence, mas na realidade ela perde. Este erro é também conhecido como Erro Tipo I \cite{baheti_classification_metrics}. 
    \item Falsos Negativos \textit{(FN - False Negatives)}: O modelo prevê que a equipe da casa perde, mas na realidade ela vence. Este erro é também conhecido como Erro Tipo II \cite{baheti_classification_metrics}.
\end{itemize}
Ao decompor as previsões nestas quatro categorias, a matriz de confusão revela não apenas quantos erros o modelo comete, mas também de que forma ele erra, o que é fundamental para o diagnóstico e aprimoramento do modelo \cite{ibm_confusion_matrix}.
\subsubsection{Acurácia}
A acurácia é a métrica mais comum e intuitiva para avaliar modelos de classificação. É calculada como a proporção de previsões corretas (TP e TN) sobre o número total de previsões realizadas\cite{coursera_confusion_matrix}. A sua fórmula é:

\[
\text{Acurácia} = \frac{TP + TN}{TP + TN + FP + FN}
\]

Apesar de sua simplicidade, a acurácia pode ser enganosa em bases com classes desbalanceadas, algo comum no esporte. Na NBA, partidas entre um líder de conferência e o lanterna ilustram esse desequilíbrio. Métricas globais como a acurácia tendem a favorecer a classe majoritária e podem ocultar a incapacidade do modelo de reconhecer casos raros. Em um cenário em que o mandante tem 90\% de probabilidade de vitória, um classificador que sempre prevê vitória do mandante atinge 90\% de acerto sem, de fato, aprender padrões úteis. 

Para a previsão de jogos da NBA, em que o objetivo é superar o conhecimento comum e as linhas de aposta, a acurácia isolada torna-se uma métrica de vaidade. Recomenda-se priorizar métricas mais avançadas ao desbalanceamento e a custos assimétricos de erro, como AUC-ROC, AUC-PR, F1, \textit{balanced accuracy}, além de medidas de calibração como \textit{Brier score} e curvas de calibração \cite{lopez}.

\subsubsection{Precisão e Recall}
Para superar as limitações da acurácia, a precisão e o recall oferecem uma avaliação mais focada na performance do modelo em relação à classe positiva.

Precisão \textit{(Positive Predictive Value - PPV)} mede a proporção de previsões positivas que estavam de facto corretas. Responde à pergunta: "Das vezes que o modelo previu uma vitória da equipe da casa, quantas vezes acertou?" \cite{fawcett2006roc}. A sua fórmula é:

$\text{Precisão} = \frac{TP}{TP + FP}$

Recall (Sensibilidade ou Taxa de Verdadeiros Positivos - TPR) mede a proporção de positivos reais que foram corretamente identificados pelo modelo. Responde à pergunta: "De todas as vitórias reais da equipe da casa, quantas é que o modelo conseguiu prever?"\cite{fawcett2006roc}. A sua fórmula é: 

$\text{Recall} = \frac{TP}{TP + FN}$

Entre estas duas métricas existe um trade-off fundamental: otimizar uma geralmente leva à degradação da outra  \cite{ibm_confusion_matrix}. Um modelo que prevê "upsets" de forma muito liberal (com base em pouca evidência) terá um recall elevado (captura a maioria dos "upsets" reais), mas uma precisão baixa (muitos falsos alarmes). Por outro lado, um modelo conservador que só prevê um "upset" com evidência muito forte terá alta precisão, mas baixo recall \cite{fawcett2006roc}.

A decisão de priorizar precisão ou recall não é puramente técnica, mas sim uma decisão estratégica que depende do objetivo do utilizador final.   
 %% pensando se eu coloco a explicação aqui eu vai ficar coisa demais

\subsubsection{F1-Score}

O F1-Score combina a precisão e o recall numa única métrica, calculada como a sua média harmónica \cite{ibm_confusion_matrix}.

$$\text{F1-Score} = 2 \times \frac{\text{Precisão} \times \text{Recall}}{\text{Precisão} + \text{Recall}}$$


Esta métrica foi concebida para fornecer uma medida de performance equilibrada, sendo particularmente útil quando as classes são desbalanceadas e quando a importância de FPs e FNs é semelhante. Ao contrário da média aritmética, a média harmónica penaliza fortemente valores extremos. Isto significa que um F1-Score elevado só é alcançado quando tanto a precisão como o recall são elevados, tornando-o um indicador mais sólido da performance geral do que a acurácia em cenários não ideais \cite{ibm_confusion_matrix}.

\begin{table}[htbp]
\caption{Resumo das Métricas de Desempenho de Classificação}
\label{tab:metricas-classificacao}
\centering
\footnotesize
\setlength{\tabcolsep}{6pt}
\renewcommand{\arraystretch}{1.25}
\newcolumntype{L}{>{\RaggedRight\arraybackslash}X}
\begin{tabularx}{\textwidth}{|l|c|L|L|L|}
\hline
Métrica & Fórmula & Pergunta respondida & Vantagen & Limitações e contexto na NBA \\
\hline
Acurácia &
$\dfrac{\mathrm{TP}+\mathrm{TN}}{\mathrm{TP}+\mathrm{TN}+\mathrm{FP}+\mathrm{FN}}$ &
Proporção de previsões corretas no total. &
Simples e intuitiva. &
Pode ser enganosa em jogos desiguais e mascarar a incapacidade de prever \textit{upsets}. \\
\hline
Precisão &
$\dfrac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}}$ &
Das previsões de vitória, quantas estavam corretas. &
Mede a confiabilidade das previsões positivas. &
Ignora falsos negativos, importante para manter credibilidade. \\
\hline
Recall &
$\dfrac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}$ &
De todas as vitórias reais, quantas foram previstas. &
Mede a capacidade de detectar eventos positivos. &
Ignora falsos positivos, pode levar à perda de oportunidades de valor. \\
\hline
F1-Score &
$2 \times \dfrac{P \times R}{P + R}$ &
Equilíbrio entre precisão e recall. &
Forte ao desbalanceamento de classes. &
Menos interpretável do que precisão e recall isoladamente. \\
\hline
\end{tabularx}

\vspace{2mm}
\footnotesize
$TP$ = verdadeiros positivos; $TN$ = verdadeiros negativos; $FP$ = falsos positivos; $FN$ = falsos negativos; $P$ = precisão; $R$ = recall.\\
Fonte: elaboração própria.
\end{table}


\subsubsection{Métricas de Discriminação}
Enquanto as métricas de desempenho avaliam o resultado final da classificação, as métricas de discriminação avaliam a capacidade intrínseca do modelo de separar as duas classes (vitória vs. derrota), independentemente de um limiar de classificação específico.


\subsubsection{Curva ROC}
As métricas da seção anterior dependem de um limiar de decisão para converter scores contínuos em classificações discretas. No entanto, este limiar é arbitrário e raramente é o ideal.1 A análise de discriminação avalia a qualidade dos scores do modelo em toda a gama de limiares possíveis \cite{fawcett2006roc}.

$$\text{FPR} = \frac{FP}{FP + TN} $$\

A curva é gerada ao variar continuamente o limiar de decisão de 1 (mais restritivo) a 0 (mais permissivo). Para cada limiar, um novo par (FPR, TPR) é calculado e plotado, formando a curva \cite{fawcett2006roc}.


\begin{itemize}
  \item Linha diagonal ($y=x$): representa um classificador aleatório, sem poder preditivo. Um modelo útil deve ter a curva acima dessa linha \cite{fawcett2006roc}.
  \item Canto superior esquerdo $(0,1)$: representa o classificador perfeito, com $\mathrm{TPR}=1$ e $\mathrm{FPR}=0$ \cite{fawcett2006roc}.
  \item Posição na curva: pontos no canto inferior esquerdo indicam comportamento conservador (baixo $\mathrm{FPR}$ e também baixo $\mathrm{TPR}$), enquanto pontos no canto superior direito indicam comportamento liberal (alto $\mathrm{TPR}$ e também alto $\mathrm{FPR}$). O gráfico torna explícito o \textit{trade-off} entre o benefício de detectar positivos e o custo de alarmes falsos \cite{fawcett2006roc}.
\end{itemize}

\subsubsection{Área Sob a Curva (AUC)}

A Área Sob a Curva (AUC) é uma métrica escalar que resume a curva ROC num único número, representando a área geométrica sob a curva. O seu valor varia entre 0.5 (para um classificador aleatório) e 1.0 (para um classificador perfeito) \cite{fawcett2006roc}.

A AUC possui uma interpretação estatística particularmente intuitiva e poderosa: é a probabilidade de que o modelo atribua uma pontuação de previsão mais alta a uma instância positiva (uma vitória real) escolhida aleatoriamente do que a uma instância negativa (uma derrota real) escolhida aleatoriamente.

Esta interpretação revela uma propriedade fundamental da AUC: ela mede a qualidade do "ranking" interno do modelo, independentemente dos valores absolutos das probabilidades. Um modelo que atribui uma probabilidade de 0.1 a todas as derrotas e 0.2 a todas as vitórias terá uma AUC perfeita de 1.0, pois consegue separar perfeitamente as classes, embora as probabilidades em si não sejam realistas. A AUC mede, portanto, a capacidade de discriminação ou separação do modelo. Um valor de AUC elevado indica que o modelo aprendeu padrões que distinguem fundamentalmente as vitórias das derrotas. É uma medida robusta da qualidade do "motor" preditivo do modelo, independente de como as suas saídas são calibradas ou de qual limiar de decisão é escolhido, tornando-a uma das métricas mais importantes para comparar o poder preditivo fundamental de diferentes modelos \cite{fawcett2006roc}.


\subsubsection{Métricas de Calibração}

A calibração avalia se as probabilidades previstas por um modelo correspondem às frequências reais dos eventos \cite{guo2017calibration}. Um modelo bem calibrado é aquele cujas previsões podem ser interpretadas como probabilidades confiáveis: para todos os casos aos quais o modelo atribui, por exemplo, 80\% de probabilidade de ocorrência, espera-se que o evento realmente ocorra em cerca de 80\% das vezes. É importante ressalta r que um modelo pode apresentar excelente discriminação isto é, elevada capacidade de distinguir entre classes, refletida por uma alta área sob a curva ROC (AUC) e ainda assim ser mal calibrado \cite{wang2025calibration}.

A má calibração é um problema recorrente em redes neurais modernas e em outros modelos complexos, que tendem a produzir previsões excessivamente confiantes (\textit{overconfident}) em relação à probabilidade real dos eventos \cite{guo2017calibration}.

Para uma avaliação quantitativa, o Brier Score é uma das métricas mais utilizadas \cite{renooij2004uncertaintruth}. Proposto originalmente para a verificação de previsões meteorológicas, ele mede o erro quadrático médio entre as probabilidades previstas ($p_i$) e os resultados reais ($o_i$, codificados como 1 para ocorrência e 0 para não ocorrência). Para previsões binárias, a fórmula é:

$$\text{Brier Score} = \frac{1}{N} \sum_{i=1}^{N} (p_i - o_i)^2$$

O Brier Score é uma proper scoring rule, o que significa que o valor mínimo esperado da métrica é alcançado apenas quando o modelo prevê as verdadeiras probabilidades. Seus valores variam de 0 a 1, onde um score mais baixo indica melhor calibração e acurácia das probabilidades. Ele combina, em uma única medida, tanto a calibração quanto a resolução (a capacidade do modelo de emitir previsões "afiadas", ou seja, próximas de 0 ou 1), tornando-se uma medida abrangente da qualidade da previsão probabilística \cite{renooij2004uncertaintruth}. 



\section{SHAP (Shapley Additive exPlanations)}

Conforme modelos de aprendizado de máquina tornaram-se mais complexos e opacos (como \textit{ensembles} de árvores ou redes neurais profundas), surgiu a necessidade de técnicas de interpretabilidade que permitam entender as predições produzidas. Dentre essas técnicas, o método SHAP (\textit{Shapley Additive exPlanations}) destacou-se pela fundamentação teórica e pela consistência das explicações geradas \cite{Lundberg2017}. O SHAP, proposto por Scott Lundberg e Su-In Lee, baseia-se no conceito de valor de Shapley da Teoria dos Jogos cooperativos. Em um jogo cooperativo, o valor de Shapley define como distribuir de forma justa a recompensa total obtida por uma coalizão de jogadores, atribuindo a cada jogador uma parcela da recompensa proporcional à sua contribuição marginal média. Analogamente, no contexto de modelos preditivos, cada “jogador” é uma \textit{feature} (variável de entrada) e a “recompensa” é a diferença entre a predição do modelo para uma instância e a predição média do modelo (ou de um baseline) \cite{Lundberg2017}. O SHAP então calcula, para uma dada instância, quanto cada feature contribuiu positiva ou negativamente para que o modelo produzisse aquele resultado em comparação a uma predição base.

Matematicamente, o SHAP pertence à classe dos métodos aditivos de explicação, cuja predição é representada como:
\[
\hat{y} = \phi_{0} + \sum_{i=1}^{M} \phi_{i},
\]
onde $\phi_{i}$ é o valor SHAP da feature $i$ \cite{Lundberg2017}. Esses valores $\phi_{i}$ são calculados considerando todas as coalizões possíveis de features sem a presença de $i$ e avaliando o impacto médio da adição de $i$ à predição (tomando a média sobre todas as ordens de inserção). Embora o cálculo exato seja computacionalmente custoso (exponencial no número de features), Scott Lundberg e Su-In Lee propuseram algoritmos de aproximação eficientes, especialmente para modelos de árvores de decisão, tornando viável a utilização do SHAP na prática.


As principais propriedades do SHAP incluem: (i) consistência, ou seja, se um modelo for alterado de forma que a contribuição marginal de uma feature aumente (mantidas as demais constantes), o valor SHAP dessa feature não diminui; (ii) localidade exata, significando que a soma dos valores SHAP de todas as features (mais o valor base $\phi_{0}$) é igual à diferença entre a predição do modelo para aquela instância e a média global \cite{Lundberg2017}. Essas propriedades garantem que as explicações sejam sensíveis e coerentes com o comportamento do modelo.

% No contexto do nosso projeto, a adoção do SHAP se justifica pela necessidade de interpretar as predições do modelo preditivo de resultados da NBA, tornando possível identificar quais fatores (estatísticas de jogo, métricas do time etc.) mais influenciaram a previsão de vitória ou derrota em uma partida. A literatura ressalta a importância da interpretabilidade em modelos esportivos, pois decisões baseadas apenas em um “palpite” de caixa-preta podem não ser confiáveis para técnicos e analistas sem uma justificativa clara \cite{Lundberg2017}.

Com o SHAP, pode-se, por exemplo, explicar por que um determinado jogo foi previsto como vitória do Time~A: os valores SHAP poderiam revelar que a excelente média de aproveitamento de arremessos do Time~A e um número superior de rebotes previstos contribuíram positivamente para a predição, enquanto o fato de o adversário jogar em casa contribuiu negativamente mas não o suficiente para reverter a tendência. Essa granularidade de explicação é valiosa, pois agrega confiabilidade ao modelo e permite insights acionáveis, por exemplo, destacar a importância de certos fundamentos do jogo.

Estudos recentes já começaram a aplicar o SHAP na área de análise esportiva: \citeonline{OuYang2025}, por exemplo, utilizaram SHAP para interpretar quais estatísticas de desempenho tinham maior peso nas vitórias de equipes da liga chinesa de basquete, demonstrando o potencial da ferramenta em extrair conhecimento mesmo de modelos complexos. Diante disso, o uso do SHAP neste projeto alinha-se com a busca por um modelo não apenas preciso, mas também transparente e explicável.

\begin{figure}[H]
    \centering
        \caption{Framework do algoritmo SHAP (2025).}
   \includegraphics[width=0.5\textwidth]{figuras/Dados (1).png}
    \legend{Fonte: Adaptado de \url{https://www.researchgate.net/figure/Framework-of-the-SHAP-algorithm_fig1_390988996}}
    \label{fig:shap-framework}
\end{figure}


\section{OTW: Optimal Time Window}

A \textit{Optimal Time Window} (OTW) é uma abordagem proposta para otimizar a seleção de dados históricos utilizados no treinamento de modelos preditivos esportivos, determinando qual intervalo temporal de partidas passadas deve ser considerado para melhor refletir o estado atual das equipes \cite{Horvat2020PhD}. A ideia central é que nem todos os jogos passados possuem a mesma relevância preditiva, jogos muito antigos podem não refletir mais a força atual de um time (devido a mudanças de elenco, técnico, estratégias), enquanto considerar apenas jogos muito recentes pode resultar em pouco volume de dados e maior volatilidade estatística \cite{Horvat2020PhD}. Assim, haveria uma “janela de tempo ótima” por exemplo, os \textit{N} jogos ou \textit{X} temporadas mais recentes que oferece o melhor balanço entre frescor dos dados e tamanho de amostra para treinar o modelo.

\citeonline{Horvat2020PhD} introduziu um método sistemático para identificar essa janela temporal ideal, integrado a um modelo de previsão de resultados de jogos de basquete. Em sua tese de doutorado, Horvat propôs um modelo adaptativo baseado em um índice de eficiência das equipes, no qual a OTW é definida de maneira a maximizar a correlação entre o índice de eficiência calculado e os resultados dos jogos \cite{Horvat2020PhD}. Em termos práticos, isso significa determinar quantos jogos ou até que ponto da temporada passada (ou temporadas passadas) devem ser utilizados no cálculo das variáveis preditivas para que estas tenham maior poder explicativo sobre o próximo jogo. Por exemplo, pode-se descobrir que usar estatísticas acumuladas das últimas 20 partidas de cada equipe produz um modelo preditivo mais acurado do que usar toda a temporada anterior ou apenas as últimas cinco partidas.

No trabalho recente de \citeonline{horvat2023}, o conceito de OTW foi incorporado em experimentos de previsão de jogos da NBA, e os resultados corroboram em parte sua utilidade. Ao testar diferentes comprimentos de janela, os autores observaram que a escolha de uma janela de tempo ótima trouxe um pequeno ganho de acurácia em relação ao uso irrestrito de todos os dados históricos disponíveis \cite{horvat2023}. Em particular, o melhor resultado (acurácia em torno de 78~\%) foi obtido treinando o modelo com dados de apenas uma temporada anterior (como janela de treino) e testando na temporada seguinte, sugerindo que dados de mais de duas temporadas atrás adicionavam mais ruído do que sinal \cite{horvat2023}. Esse achado está alinhado com a intuição de que a NBA está em constante evolução jogadores transferem-se, novos talentos surgem, times mudam de estratégia e, portanto, limitar a abrangência temporal do treinamento pode ajudar o modelo a se concentrar em padrões mais pertinentes ao momento atual.

Cabe ressaltar, que determinar a OTW ideal não é trivial e demanda testes experimentais para sua definição adequada. \citeonline{horvat2023} reconhecem que sua implementação da OTW trouxe ganhos modestos e sugerem que há espaço para aprimorar o cálculo dessa janela \cite{horvat2023}. Questões em aberto incluem como adaptar dinamicamente a janela à medida que novas partidas ocorrem (por exemplo, dar mais peso aos jogos mais recentes dentro da janela) e como proceder quando existem poucos confrontos diretos recentes entre dois times (caso em que poderia ser relevante ampliar a janela especificamente para incluir mais partidas entre eles) \cite{horvat2023}. Apesar desses detalhes em evolução, o conceito de OTW traz para a modelagem preditiva uma preocupação importante: a de que a pertinência dos dados de treino não é uniforme ao longo do tempo, e que estratégias que priorizam informações mais atualizadas tendem a melhorar a capacidade de previsão em domínios dinâmicos como o esporte.

No contexto deste projeto, a utilização de uma OTW visa garantir que o modelo de previsão esteja sempre treinado com dados suficientemente recentes para refletir a performance atual das equipes, sem entretanto descartar tantos dados a ponto de perder significância estatística. Com base na literatura \cite{Horvat2020PhD,horvat2023}, espera-se que essa abordagem contribua para um modelo mais adaptado às condições vigentes em cada período da liga, complementando as demais técnicas empregadas.

\begin{figure}[H]
    \centering
    \caption{Ilustração das Janelas Temporais Ótimas (OTWs, em verde) e sua relação com os intervalos de tempo dos conjuntos de dados de treinamento (em azul claro), para N jogos do time observado.}
    \includegraphics[width=0.7\textwidth]{figuras/1 temporada (2).png} 

    \legend{Fonte: Adaptado \citeonline{horvat2023}}
    \label{fig:otw-illustration}
\end{figure}


\section{Trabalhos Relacionados}

Uma linha de pesquisa envolve \textit{ensembles} heterogêneos, combinando diferentes tipos de modelos preditivos. \citeauthor{Albert2021} integraram algoritmos de \textit{boosting} com redes neurais para prever a seleção de jogadores no All-Star Game da NBA, obtendo melhora de acurácia nas predições e acrescentando certa interpretabilidade por meio da análise das importâncias de atributos \cite{Albert2021}.

Outra vertente destacada na literatura diz respeito ao horizonte temporal dos dados utilizados para treino de modelos. \citeauthor{horvat2023} propuseram restringir o conjunto de treinamento a uma “janela” temporal dinâmica, de modo a refletir apenas a forma recente das equipes e atenuar a influência de dados históricos possivelmente defasados \cite{horvat2023}. Esse conceito de \textit{Janela Temporal Ótima} (OTW) resultou em ganhos modestos de desempenho, por exemplo, ao considerar somente os jogos da temporada imediatamente anterior para treinar um modelo preditivo, obteve-se acurácia em torno de 78\% -- superior ao treinamento com múltiplas temporadas, que pode introduzir ruído \cite{horvat2023}.

Também vêm ganhando espaço abordagens que integram predição e explicação. Métodos de interpretabilidade como o SHAP \cite{Lundberg2017} têm sido aplicados para tornar modelos de \textit{gradient boosting} menos opacos, embora seu uso específico em predição de partidas de basquete ainda seja incipiente. \citeauthor{ouyang2024}, por exemplo, combinaram um modelo XGBoost com a análise SHAP para identificar os fatores mais determinantes nos resultados de jogos da NBA, e relataram que métricas como aproveitamento de arremessos de quadra, rebotes defensivos e número de desperdícios de posse estão consistentemente entre as mais influentes para definir o vencedor de uma partida \cite{ouyang2024}.

Contudo, uma crítica recorrente a muitos modelos preditivos é sua dependência excessiva de estatísticas agregadas por equipe, que podem mascarar a dinâmica interna do elenco. Como apontam \cite{wang2025}, modelos baseados apenas na força histórica da equipe possuem poder explicativo limitado, e a inclusão de dados sobre lesões melhora significativamente a acurácia. Essa vulnerabilidade é reforçada por \cite{articleWu}, que descreve a lesão de um jogador-chave como uma 'influência vital' capaz de reverter o resultado esperado mesmo entre equipes com grande disparidade de força. Além das lesões, modelos que utilizam dados agregados de time 'não conseguem levar em conta rapidamente as mudanças no elenco', como trocas e contratações, o que representa uma falha estrutural, especialmente no início de novas temporadas.

Por fim, estudos recentes sugerem que a combinação de métricas individuais de jogadores com estatísticas coletivas de equipes eleva o poder preditivo dos modelos. O modelo híbrido \textit{MambaNet}, apresentado por \citeauthor{khanmohammadi2024}, exemplifica essa estratégia ao processar simultaneamente séries históricas de desempenho de times e de jogadores para estimar probabilidades de vitória e classificação aos playoffs \cite{khanmohammadi2024, mambanet2024}. Essa incorporação de dados em nível de jogador permitiu ao MambaNet superar abordagens baseadas apenas em estatísticas agregadas por equipe \cite{khanmohammadi2024}.


% ========================================================================
% DESENVOLVIMENTO
% ========================================================================

\chapter{Metodologia}

\section{Fonte e Coleta de Dados}

Os dados primários foram extraídos por meio de consultas à \textit{API-NBA}, uma interface de programação de aplicações (API) comercialmente disponível. A escolha desta fonte justifica-se pela sua capacidade de fornecer dados estruturados, consistentes e de alta granularidade, atendendo às necessidades específicas do modelo em dois níveis: dados em nível de jogo e dados em nível de jogador. O primeiro consiste em um conjunto contendo o registro de cada partida, detalhando as equipes mandante e visitante, a data do confronto e os placares finais. O segundo consiste em um conjunto granular que contém as estatísticas individuais (\textit{box score}) de cada atleta para cada partida disputada.

Adicionalmente, para complementar os dados históricos com informações sobre a disponibilidade atual dos elencos, foi implementado um processo de \textit{web scraping} no portal ESPN. Este processo extrai diariamente os \textit{depth charts} de cada equipe, identificando os jogadores titulares e reservas para cada posição, bem como o status de lesões reportado. Para garantir a robustez da coleta de dados via API e \textit{scraping}, foram implementadas estratégias de múltiplas tentativas de requisição, pausas exponenciais em caso de limites atingidos e intervalos regulares entre chamadas, minimizando falhas e respeitando os termos de uso das fontes.

O escopo temporal dos dados abrange as temporadas regulares da \textit{National Basketball Association} a partir de 2021--2022 até a data de execução do processo de coleta (novembro de 2025), garantindo uma base de dados robusta para a análise.


\section{Tratamento de Vazamento Temporal}

Uma preocupação central na modelagem de séries temporais é o vazamento de dados (\textit{data leakage}), onde o modelo, durante o treinamento ou validação, inadvertidamente tem acesso a informações que não estariam disponíveis no momento da previsão real. No contexto de previsão de jogos, usar dados do próprio dia do jogo ou de dias futuros para calcular atributos preditivos comprometeria a validade da avaliação do modelo.

Para mitigar esse risco e garantir a causalidade estrita, foram implementadas duas salvaguardas principais:
\begin{enumerate}
    \item Buffer Temporal na Engenharia de Atributos: Foi utilizada uma função que aplica um \textit{buffer} temporal, geralmente de 1 dia (24 horas). Ao calcular os atributos para um jogo ocorrendo na data $T$, essa função assegura que apenas dados de jogos ocorridos estritamente antes de $T$ (ou seja, até $T-1$) sejam consultados. Isso simula realisticamente a informação disponível no momento da previsão.
    \item Embargo na Validação Cruzada: Durante a validação cruzada temporal, um período de ``embargo'' de 1 dia foi introduzido entre o final do conjunto de treinamento e o início do conjunto de validação. Isso evita que a performance na validação seja influenciada por dados muito próximos (ou do mesmo dia) aos últimos dados usados no treino, como ilustrado na Figura \ref{fig:uml_seq_embargo}.
\end{enumerate}

Essas medidas asseguram que a avaliação do modelo reflita de forma mais fidedigna seu desempenho esperado em um cenário de previsão operacional.

\begin{figure}[H]
    \centering
    \caption{Buffer temporal na engenharia de atributos}
    \includegraphics[width=0.65\textwidth]{umls/bufferTemporaç.png}
    \caption*{
        \small
        Representação do procedimento de buffer temporal para evitar vazamento temporal. 
        A partir do jogo-alvo na data $T$, define-se a "data segura" em $T-24$ h. 
        Filtram-se nas bases de Partidas e de Estatísticas de Jogadores apenas registros 
        anteriores a essa data. Os atributos do jogo-alvo são construídos somente com 
        informações disponíveis até $T-1$ dia. Nenhum dado de $T$ ou do futuro é utilizado.
        
        \vspace{1mm}
        \textit{Fonte:} Elaboração própria (2025)
    }
    \label{fig:buffer-temporal}
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Embargo na validação cruzada temporal.}
    \includegraphics[width=0.65\textwidth]{umls/embargo.png}
    \caption*{
        \small
        Legenda: esquema do embargo para evitar vazamento temporal. Em cada dobra define-se a janela de teste [T .. T{+}k] e aplica-se um embargo de 24 horas imediatamente anterior a T. O treino usa apenas registros com data < T - 24 h. A validação usa registros em [T .. T{+}k]. O processo se repete para todas as dobras.
        
        \textit{Fonte:} Elaboração própria (2025)
    }
    \label{fig:embargo-temporal}
\end{figure}

\section{Dataset de Jogos}

O primeiro conjunto de dados contém informações agregadas para cada partida disputada no período analisado. Cada linha representa um único jogo e inclui as seguintes colunas principais:

\begin{itemize}
    \item \texttt{game\_id}: Identificador numérico único para cada partida. Serve como chave primária para relacionar com os dados de jogadores.
    \item \texttt{date}: Data e hora de início da partida, em formato UTC. Utilizada para ordenação cronológica e cálculos temporais.
    \item \texttt{home\_team\_code} / \texttt{away\_team\_code}: Códigos de três letras identificando as equipes mandante e visitante (e.g., 'LAL' para Los Angeles Lakers).
    \item \texttt{home\_team\_name} / \texttt{away\_team\_name}: Nomes completos das equipes mandante e visitante.
    \item \texttt{home\_score} / \texttt{away\_score}: Pontuação final das equipes mandante e visitante.
    \item \texttt{arena}: Nome da arena onde o jogo foi disputado.
    \item \texttt{city}: Cidade onde a arena está localizada.
    \item \texttt{season}: Ano da temporada correspondente (e.g., 2021 para a temporada 2021-2022).
    \item \texttt{status}: Status final do jogo (e.g., 'Finished').
\end{itemize}

Este dataset fornece o contexto geral de cada confronto, incluindo o resultado final, que é fundamental para a definição da variável alvo (\texttt{home\_win}).

\section{Dataset de Estatísticas de Jogadores}

O segundo conjunto de dados oferece uma visão granular do desempenho individual dos atletas em cada partida. Cada linha representa as estatísticas de um jogador específico em um determinado jogo, vinculada ao jogo correspondente através do \texttt{game\_id}. As colunas mais relevantes incluem:

\begin{itemize}
    \item \texttt{game\_id}: Chave estrangeira que referencia o jogo no dataset de partidas.
    \item \texttt{date}: Data e hora da partida.
    \item \texttt{team\_code}: Código da equipe pela qual o jogador atuou na partida.
    \item \texttt{player\_id}: Identificador numérico único para cada jogador.
    \item \texttt{player\_name}: Nome completo do jogador.
    \item \texttt{pos}: Posição primária do jogador (e.g., 'G' para \textit{Guard}, 'F' para \textit{Forward}, 'C' para \textit{Center}). Pode estar vazia.
    \item \texttt{min}: Minutos jogados na partida (formato texto, e.g., '30:15' ou vazio).
    \item \texttt{points}: Total de pontos marcados.
    \item \texttt{fgm}, \texttt{fga}, \texttt{fgp}: Cestas de campo convertidas (\textit{made}), tentadas (\textit{attempted}) e percentual de acerto (\textit{percentage}).
    \item \texttt{ftm}, \texttt{fta}, \texttt{ftp}: Lances livres convertidos, tentados e percentual.
    \item \texttt{tpm}, \texttt{tpa}, \texttt{tpp}: Arremessos de três pontos convertidos, tentados e percentual.
    \item \texttt{offReb}, \texttt{defReb}, \texttt{totReb}: Rebotes ofensivos, defensivos e totais.
    \item \texttt{assists}: Número de assistências.
    \item \texttt{steals}: Número de roubos de bola.
    \item \texttt{blocks}: Número de tocos.
    \item \texttt{turnovers}: Número de perdas de bola (\textit{turnovers}).
    \item \texttt{pFouls}: Número de faltas pessoais.
    \item \texttt{plusMinus}: Saldo de pontos da equipe enquanto o jogador esteve em quadra (pode ser formato texto ou numérico).
\end{itemize}

Este dataset é a fonte primária para a engenharia de atributos relacionados ao desempenho recente dos jogadores e das equipes, permitindo calcular médias ponderadas, consistência e outras métricas que alimentam o modelo.

Combinados, esses dois datasets fornecem uma base detalhada para a modelagem. O dataset de jogos estabelece o resultado e o contexto de cada evento, enquanto o dataset de jogadores permite a análise do desempenho que levou a esse resultado. A estrutura relacional, unida pelo id da partida, possibilita a criação de atributos que consideram tanto o histórico das equipes quanto a performance individual recente dos atletas.

A etapa de engenharia de atributos (\textit{feature engineering}) é importante para transformar os dados brutos coletados e tratados em variáveis preditivas informativas que possam ser efetivamente utilizadas pelo modelo. O objetivo principal foi criar atributos que capturassem não apenas o desempenho médio histórico das equipes e jogadores, mas também a dinâmica temporal, a forma recente, a consistência, o contexto do calendário e as interações específicas de cada confronto.

Para cada jogo no dataset, um conjunto de atributos foi calculado com base estritamente nos dados históricos disponíveis até o dia anterior à partida, garantindo a prevenção de vazamento temporal através da função, conforme detalhado no Capítulo 3.

\section{Engenharia de Features}

A etapa de engenharia de atributos (\textit{feature engineering}) é importante para transformar os dados brutos coletados e tratados em variáveis preditivas informativas que possam ser efetivamente utilizadas pelo modelo. O objetivo principal foi criar atributos que capturassem não apenas o desempenho médio histórico das equipes e jogadores, mas também a dinâmica temporal, a forma recente, a consistência, o contexto do calendário e as interações específicas de cada confronto.

\subsection{Atributos Baseados no Histórico de Jogos}

Para refletir o desempenho recente das equipes de forma mais precisa do que médias móveis simples, foram implementadas duas técnicas principais: a Janela Temporal Ótima (OTW) e a Ponderação Exponencial Dinâmica.

\subsubsection{Janela Temporal Ótima (OTW)}
A OTW determina dinamicamente o número de jogos passados ($N$) a serem considerados para cada equipe antes de uma partida específica. A janela base é de 10 jogos, com limites mínimo de 5 e máximo de 20. Esse tamanho é ajustado heuristicamente com base em:
\begin{itemize}[noitemsep, topsep=0pt]
    \item Fase da Temporada: janelas menores no início da temporada (menos de 30 dias) e ligeiramente maiores no final (mais de 150 dias).
    \item Volatilidade Recente: medida pelo coeficiente de variação do \textit{net rating} nos últimos 10 jogos. Alta volatilidade ($>$ 1.5) reduz a janela, enquanto baixa volatilidade ($<$ 0.5) a aumenta.
    \item Trocas na rotação: quando há alteração relevante entre os oito jogadores mais utilizados nas duas semanas anteriores (sobreposição inferior a 70\%), a janela é reduzida ao mínimo de 5 jogos.
    \item Densidade de Jogos: muitos jogos na última semana ($\ge 4$) reduzem a janela, poucos jogos ($\le 1$) a aumentam.
    \item Mudança de Performance: compara o \textit{net rating} médio na janela atual com o período anterior de mesmo tamanho. Uma diferença grande ($>$ 10 pontos) sugere uma mudança de fase e encurta a janela.
\end{itemize}


Para cada confronto, adota-se como janela efetiva a menor OTW entre a equipe mandante e a visitante. Essa escolha garante que ambas sejam avaliadas com históricos recentes de tamanho comparável, evitando distorções por janelas desbalanceadas.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{umls/otw.png}
    \caption{Fluxo de cálculo da Janela Temporal Ótima (OTW) por time}
    \caption*{
        \small
        Parâmetros}: MIN=5, BASE=10, MAX=20 jogos.\par
        Fase da temporada: início~(<30 dias) usa janela menor; final~(>150 dias) levemente maior.\par
        Volatilidade (CV): coeficiente de variação do \textit{net rating} nos últimos 10 jogos; CV>1{,}5 reduz a janela; CV<0{,}5 aumenta.\par
        Mudança de rotação: sobreposição $<70\%$ entre os 8 jogadores com mais minutos nas últimas 2 semanas $\Rightarrow$ janela mínima.\par
        Densidade de jogos (7 dias): $\geq 4$ jogos reduz; $\leq 1$ jogo aumenta.\par
        Mudança de performance: $|\overline{NR}_{\text{recente}}-\overline{NR}_{\text{anterior}}|>10$ pontos reduz a janela.\par
        Saída: $window$ inteiro após ajustes.
        
        \vspace{1mm}
        \textit{Fonte:} Elaboração própria (2025)
    }
    \label{fig:otw-calculo-time}
\end{figure}

\subsubsection{Ponderação Exponencial Dinâmica}
Dentro da OTW selecionada, nem todos os jogos têm a mesma relevância: partidas mais recentes e equipes mais estáveis tendem a ser mais preditivas. Adota-se um esquema de ponderação por decaimento exponencial, em que o peso \(w_i\) de um jogo \(i\), ocorrido \(d_i\) dias antes da data de referência, é dado por
\[
w_i \propto \exp(-\lambda\, d_i).
\]
A taxa de decaimento \(\lambda\) é adaptativa e modulada pela volatilidade recente \((\sigma)\) do \textit{net rating} da equipe: \(\lambda = 0{,}05\, (1 + \sigma/10)\). Times mais instáveis (maior \(\sigma\)) recebem um \(\lambda\) maior, de modo que os jogos antigos perdem influência mais rapidamente. Os pesos são normalizados para somar 1. Todas as métricas baseadas no histórico (por exemplo, médias e desvios padrão) são calculadas de forma ponderada por esses pesos dinâmicos.

\subsubsection{Atributos Derivados do Histórico}
Com a OTW e a ponderação dinâmica, foram calculados, para mandante e visitante, os seguintes atributos:
\begin{itemize}[noitemsep, topsep=0pt]
    \item desempenho geral: taxa de vitórias, média de pontos marcados, média de pontos sofridos e saldo de pontos (\textit{net rating});
    \item sequências recentes: comprimento da sequência atual de vitórias ou derrotas consecutivas;
    \item \textit{momentum} de curto prazo: saldo de vitórias nos três jogos mais recentes;
    \item volatilidade ofensiva: desvio padrão ponderado dos pontos marcados na janela;
    \item eficácia casa/fora: nos últimos 15 jogos em casa (mandante) ou fora (visitante), taxa de vitória e médias de pontos marcados e sofridos.
\end{itemize}


\section{Atributos Baseados em Estatísticas de Jogadores}

Para capturar o impacto do desempenho individual e da composição do elenco, adotou-se um procedimento que, antes de cada jogo, analisa as estatísticas dos atletas em um período recente (30 dias por padrão, ajustado quando há poucos dados). Assim como no histórico de jogos, aplica-se ponderação por recência via decaimento exponencial, de modo que partidas mais novas pesem mais do que antigas.

\subsection{Agregação Ponderada}
As estatísticas de cada jogador (pontos, rebotes, assistências, \textit{plus-minus}, percentuais de arremesso, entre outras) são resumidas por médias ponderadas com base na recência dos jogos daquele atleta. Em seguida, essas médias por jogador são combinadas no nível do time utilizando um peso adicional proporcional à importância do atleta na rotação, aproximada pelo produto entre os minutos médios em quadra e o número de partidas disputadas no período recente. Com isso, jogadores mais utilizados influenciam mais os atributos agregados da equipe.

\subsection{Atributos Gerados dos Jogadores}
A partir dessa consolidação, foram construídos, para cada equipe:
\begin{itemize}[noitemsep, topsep=0pt]
    \item médias agregadas das estatísticas básicas de \textit{box score} no nível do time (pontos, rebotes, assistências, \textit{plus-minus}, acurácias de arremesso, etc.);
    \item indicadores dos cinco atletas com maior média de minutos, reportando suas médias de pontos, rebotes, assistências e \textit{plus-minus} (retrato do núcleo da rotação);
    \item medidas de consistência e profundidade do elenco: consistência ofensiva obtida por \(1 - \text{CV}\) das médias de pontos entre jogadores, e contagem de atletas com média ponderada superior a 8 pontos (profundidade);
    \item escores heurísticos de ataque e defesa do elenco: o ofensivo combina produção de pontos, eficiência de arremessos e criação de jogadas; o defensivo combina roubos e tocos, com penalização para perdas de bola.
\end{itemize}

\section{Atributos Contextuais e Derivados}

Além das métricas de desempenho baseadas no histórico, outros atributos foram criados para fornecer contexto adicional:

\begin{itemize}[noitemsep, topsep=0pt]
    \item Descanso e agenda: dias desde a última partida, indicador de jogos em dias consecutivos (\textit{back-to-back}) e quantidade de partidas nos sete dias anteriores.
    \item Confronto direto (H2H): taxa de vitórias do mandante nos cinco encontros mais recentes contra o visitante, desconsiderando partidas da mesma semana para evitar dependências imediatas.
    \item Temporais: mês, dia da semana, marcador de fim de semana, dias decorridos desde o início da temporada e fase da temporada (início, meio, fim).
    \item Diferenças mandante–visitante: para a maior parte das métricas de ambos os lados (taxa de vitória, saldo de pontos, descanso, momento, sequência, médias de jogadores), calcula-se a diferença direta (mandante menos visitante). Exemplos: vantagem de taxa de vitória, vantagem de saldo de pontos, vantagem de descanso e diferença nas médias agregadas de jogadores. Essas diferenças capturam a vantagem relativa em múltiplas dimensões.
    \item Matchups ataque–defesa: comparação direta entre a produção ofensiva de um time e a solidez defensiva do adversário, como a diferença entre a média de pontos marcados por uma equipe e a média de pontos sofridos pela oponente.
\end{itemize}

Esse conjunto de atributos combinando histórico ponderado, estatísticas de jogadores, contexto de calendário e comparações diretas forma a base de entrada do modelo apresentado no capítulo seguinte. A Tabela \ref{tab:lista_features} pode listar, de forma completa, cada atributo e sua descrição.

\section{Validação Temporal com Embargo}

\subsection{Justificativa da validação temporal}
Dados esportivos são sequenciais: o futuro não pode “vazar” para o passado. Métodos aleatórios de validação cruzada superestimariam o desempenho por misturar jogos posteriores aos que estão sendo previstos. Para refletir o uso real do sistema, adotou-se validação estritamente cronológica.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figuras/validacaoTemporal.png}
\caption{Pipeline de validação temporal: etapas e laço de dobras}
\legend{Fonte: elaboração própria.}
\label{fig:walkforward_sequencia}
\end{figure}



\subsection{Estratégia implementada}
Aplicou-se o esquema \textit{walk-forward} com três dobras. Entre o fim de cada conjunto de treino e o início do conjunto de validação impôs-se um embargo de um dia, eliminando sobreposições. Cada dobra respeitou tamanhos mínimos de 50 jogos para treino e 10 para teste, garantindo consistência estatística. A figura correspondente ilustra, com datas fictícias, a composição dessas dobras.

\begin{figure}[H]
\centering
\includegraphics[width=0.4\textwidth]{figuras/walkFoward.png}
\caption{Validação temporal com embargo em esquema \textit{walk-forward}}
\legend{Elaboração própria}
\label{fig:walkforward_atividade}
\end{figure}



\section{Seleção e Configuração do Modelo}
\label{sec:selecao_modelo}

\subsection{Escolha do algoritmo}
Utilizou-se o CatBoost, um método de \textit{gradient boosting} em árvores, adequado para dados tabulares com muitos atributos categóricos (como equipes, mês e fase da temporada), sem exigir codificação manual extensa. Seu mecanismo de treinamento evita vazamento do alvo durante a construção das estatísticas categóricas, e o uso de árvores simétricas favorece previsões rápidas e controle de sobreajuste. 


\subsection{Otimização de hiperparâmetros}
A calibração dos hiperparâmetros foi feita por otimização Bayesiana (via Optuna), sempre avaliando cada proposta com a mesma validação temporal já descrita. O espaço de busca incluiu número de iterações, profundidade das árvores, taxa de aprendizado, regularização L2 e amostragem de linhas e colunas. A Tabela \ref{tab:optuna_results} ilustra uma amostra dos experimentos e o melhor resultado pela métrica AUC.

\begin{table}[H]
    \centering
    \caption{Otimização de hiperparâmetros (amostra).}
    \label{tab:optuna_results}
    \begin{tabular}{ccccccc}
        \toprule
        Trial & Iterações & Profundidade & Taxa de aprend. & L2 & AUC (val.) & Tempo \\
        \midrule
        1 & 250 & 5 & 0{,}030 & 5{,}0 & 0{,}664 & 2{,}3s \\
        2 & 764 & 5 & 0{,}027 & 8{,}2 & 0{,}691 & 5{,}1s \\
        3 & 500 & 7 & 0{,}040 & 3{,}0 & 0{,}673 & 4{,}2s \\
        \dots & \dots & \dots & \dots & \dots & \dots & \dots \\
        \midrule
        Melhor & 764 & 5 & 0{,}027 & 8{,}2 & 0{,}691 & 5{,}1s \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Configuração final}
O modelo final foi treinado no bloco de treino (80\% mais antigo) com os hiperparâmetros selecionados:
\begin{itemize}[noitemsep, topsep=0pt]
    \item iterações: 764 (com parada antecipada);
    \item profundidade das árvores: 5;
    \item taxa de aprendizado: \(\approx 0{,}027\);
    \item regularização L2: \(\approx 8{,}17\);
    \item amostragem de linhas: \(\approx 0{,}96\);
    \item amostragem de colunas: \(\approx 0{,}998\);
    \item função de perda: logloss;
    \item métrica de avaliação: AUC.
\end{itemize}

As variáveis categóricas (equipes, mês, dia da semana, fim de semana e fase da temporada) foram informadas explicitamente para tratamento nativo.

\section{Tratamento de Variáveis Categóricas}
\label{sec:tratamento_categoricas}

\subsection{Codificação ordenada}
As categorias foram transformadas em valores numéricos por estatísticas do alvo calculadas de forma ordenada, isto é, cada exemplo vê apenas informação de exemplos “anteriores” em uma permutação dos dados. Esse procedimento reduz vazamento e estabiliza categorias raras por meio de um \textit{prior}. Em termos gerais, o valor numérico atribuído a uma categoria combina a média histórica do alvo para aquela categoria (considerando apenas observações anteriores) e uma ancoragem na média global, regularizada para não supervalorizar categorias com poucos exemplos.

\subsection{Quais categorias foram usadas}
A Tabela \ref{tab:cat_features} lista os atributos categóricos usados pelo modelo.

\begin{table}[H]
    \centering
    \caption{Variáveis categóricas utilizadas.}
    \label{tab:cat_features}
    \begin{tabular}{lcc}
        \toprule
        Categoria & Valores únicos (aprox.) & Tipo \\
        \midrule
        Time mandante & 30 & Identificador \\
        Time visitante & 30 & Identificador \\
        Mês & 12 & Cíclico/ordinal \\
        Dia da semana & 7 & Cíclico/ordinal \\
        Fim de semana & 2 & Binário \\
        Fase da temporada (início/meio/fim) & 3 & Nominal \\
        \bottomrule
    \end{tabular}
\end{table}


\section{Análise de Ablação}

Para quantificar a contribuição de grupos de variáveis, conduziu-se uma análise de ablação com três configurações. O modelo completo, com todos os atributos de equipe, contexto e agregações de jogadores. Um modelo reduzido com apenas atributos básicos de equipe e calendário. E um modelo idêntico ao completo, porém sem os atributos derivados de jogadores. Os resultados foram comparados no mesmo esquema temporal de avaliação.


\section{Explicabilidade das Predições}

Para entender como o modelo chega às previsões, aplicou-se o método SHAP no conjunto de teste temporal. Foram calculados valores contribucionais por jogo e consolidações por grupos de variáveis. As visualizações permitem observar, caso a caso, quais fatores empurraram a probabilidade para cima ou para baixo. Em nível agregado, os rankings de importância destacaram diferenças mandante versus visitante em desempenho recente, indicadores de descanso e componentes derivados de jogadores como elementos com maior impacto.

Essa leitura oferece dois ganhos. Aumenta a transparência do sistema, pois torna explícitas as razões das previsões. E orienta aprimoramentos, indicando quais variáveis acrescentam valor e quais podem ser simplificadas.

\section{Análise de Limiar de Decisão}

Foi estudado o efeito de diferentes limiares de decisão na conversão de probabilidades em classes. Avaliar apenas o corte em 0{,}50 pode ocultar pontos de operação mais adequados ao objetivo do usuário. Testaram-se limiares em passos regulares e registraram-se acurácia, precisão e recall em cada ponto. Observou-se que certos limiares produzem ganhos de precisão com perdas modestas de recall, ou o inverso, permitindo selecionar o ponto de operação conforme a preferência por minimizar falsos positivos ou falsos negativos.

\section{Acurácia por Equipe e ao Longo do Tempo}

A avaliação também foi detalhada por equipe e por período. A acurácia por equipe revelou variação associada à estabilidade do elenco e à constância tática. Conjuntos com menos mudanças apresentaram desempenho mais alto. Séries mensais mostraram oscilações compatíveis com fases de temporada, sequência de jogos em curto intervalo e ausências de atletas. Essa análise contextualiza limites e fortalezas do modelo e aponta frentes específicas de melhoria.

\section{Aplicação em Cenário de Uso}

Para demonstrar a aplicação prática, executou-se um procedimento de previsão para um jogo futuro com dados verossímeis disponíveis antes da partida. O fluxo seguiu as mesmas salvaguardas temporais adotadas no treinamento. Primeiro, reuniram-se as informações recentes de equipes e jogadores até a véspera do confronto. Em seguida, calcularam-se os atributos exatamente no mesmo formato utilizado pelo modelo. Por fim, obteve-se a probabilidade de vitória e a classe prevista, opcionalmente ajustando o limiar conforme a análise anterior.

Essa demonstração ilustra como o método pode ser operado em ambiente real. O mesmo fluxo serve para integrar o modelo a um processo periódico de geração de probabilidades, desde que respeitados os cuidados de atualização de dados e de avaliação contínua de calibração.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{figuras/jogosFuturos.png}
\caption{Fluxo de previsão em cenário de uso com embargo de 24 horas}
\legend{Fonte: elaboração própria.}
\label{fig:cenario_uso_sequencia}
\end{figure}



% ========================================================================
% CAPÍTULO 4: TESTES E RESULTADOS
% ========================================================================
\chapter{Testes e Resultados}
\label{cap:testes_resultados}

\section{Configuração experimental}
\label{sec:config_exp}
Os experimentos foram executados em ambiente Python 3.10 com as bibliotecas CatBoost, Optuna, Scikit-learn, Pandas e SHAP. A base histórica compreende jogos e estatísticas individuais de jogadores da NBA a partir de 2021 até 27 de dezembro de 2024 para treino. O conjunto de teste é composto por 783 jogos ocorridos entre 28 de dezembro de 2024 e 25 de outubro de 2025. Todas as rotinas respeitam a cronologia e aplicam embargo temporal de 24 horas, tanto na engenharia de atributos quanto na validação, conforme descrito no Capítulo 3.

\section{Otimização de hiperparâmetros}
\label{sec:optuna}
A busca por hiperparâmetros foi realizada com validação temporal e métrica AUC como função-objetivo. Observou-se melhor desempenho com profundidades intermediárias, taxa de aprendizado baixa e regularização L2 moderada. A Tabela \ref{tab:optuna_top} ilustra uma amostra dos melhores ensaios.

\begin{table}[H]
\centering
\caption{Melhores ensaios de otimização de hiperparâmetros (amostra)}
\label{tab:optuna_top}
\footnotesize
\begin{tabular}{ccccccc}
\hline
Ensaio & Iterações & Profundidade & Taxa de aprend. & L2 & AUC (val.) & Tempo \\
\hline
1  & 250 & 5 & 0,030 & 5,0  & 0,664 & 2,3 s \\
2  & 764 & 5 & 0,027 & 8,2  & 0,691 & 5,1 s \\
3  & 500 & 7 & 0,040 & 3,0  & 0,673 & 4,2 s \\
\ldots & \ldots & \ldots & \ldots & \ldots & \ldots & \ldots \\
Melhor & 764 & 5 & 0,027 & 8,2 & 0,691 & 5,1 s \\
\hline
\end{tabular}
\end{table}

\section{Desempenho geral}
\label{sec:desempenho_geral}
O classificador final atingiu desempenho superior à linha de base. Os valores a seguir foram obtidos no conjunto de teste cronológico.

\begin{table}[H]
\centering
\caption{Métricas globais no conjunto de teste}
\label{tab:metricas_globais}
\footnotesize
\begin{tabular}{lc}
\hline
Métrica & Valor \\
\hline
Acurácia & 65,64\% \\
AUC-ROC & 0,7036 \\
F1-Score & 0,656 \\
Brier Score & 0,217 \\
Linha de base (acurácia) & 53,77\% \\
\hline
\end{tabular}
\end{table}

O modelo ficou 11,88 p.p. mais preciso que a linha de base. A AUC-ROC de 0,7036 confirma boa discriminação entre vitórias e derrotas. Após calibração isotônica, observou-se redução do desvio médio entre probabilidade prevista e frequência observada.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figuras/roc_pr_curves.png}
\caption{Curvas ROC e Precision–Recall no conjunto de teste. A linha tracejada representa, respectivamente, o classificador aleatório (ROC) e a precisão média (PR).}
\legend{Fonte: elaboração própria.}
\label{fig:roc_pr_curves}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figuras/gain_lift_curves.png}
\caption{Curvas de Ganho e de \textit{Lift} no conjunto de teste. À esquerda, o ganho acumulado de acertos ao ordenar a amostra por probabilidade prevista; a linha pontilhada indica o desempenho aleatório. À direita, o \textit{lift} (multiplicador do acerto vs.\ aleatório) por fração da amostra, com linha base em 1{,}0. Observa-se maior ganho nos decis iniciais e \textit{lift} $\approx 1{,}6$–$1{,}7$ no topo, decaindo gradualmente até 1{,}0.}
\legend{Fonte: elaboração própria.}
\label{fig:gain_lift}
\end{figure}


\section{Análises detalhadas}
\label{sec:analises_detalhadas}

\subsection{Acurácia por equipe}
\label{subsec:acc_por_equipe}

A análise por equipe refere-se ao modelo treinado até o final da temporada 2024–2025 e testado nos jogos subsequentes, incluindo o início da temporada 2025–2026. A heterogeneidade entre equipes permanece evidente e relaciona-se a fatores estruturais da liga e à composição dos elencos.

O Oklahoma City Thunder apresentou 80{,}65\% de acerto em 63 jogos, desempenho que se explica em parte pela continuidade do núcleo principal (Shai Gilgeous-Alexander, Jalen Williams e Chet Holmgren) e pela estabilidade de escalações ao longo das últimas temporadas. Essa consistência permite que variáveis de desempenho recente e sinergia de elenco capturem padrões mais previsíveis, o que reduz ruído nas janelas temporais do modelo.

Por outro lado, o Indiana Pacers obteve 56{,}45\% de acerto em 62 jogos, com forte assimetria entre mando e visita: 70{,}59\% como mandante e 39{,}29\% como visitante. Parte dessa diferença decorre do estilo de jogo acelerado e da maior variância ofensiva, que aumenta a imprevisibilidade fora de casa. Além disso, o time passou por mudanças na rotação no segundo semestre de 2025, o que impactou diretamente a coerência das variáveis agregadas de jogadores. % citar dps

Casos intermediários, como Los Angeles Lakers (64{,}71\%) e Denver Nuggets (64{,}62\%), reforçam o papel do mando de quadra e da sequência de calendário. O Charlotte Hornets destacou-se com 72{,}92\% de acerto, impulsionado por vitórias inesperadas fora de casa (84{,}62\% como visitante), mas com amostra reduzida que eleva a incerteza estatística.

Essas diferenças não representam falhas do modelo, mas refletem variação estrutural entre franquias, já observada em estudos anteriores de previsão esportiva \cite{horvat2023}. Modelos baseados em histórico recente tendem a favorecer equipes de comportamento estável, enquanto times em reconstrução ou com grande rotatividade de atletas produzem flutuações maiores nas métricas preditivas. A incorporação de variáveis de entrosamento e estabilidade de \textit{lineup} pode atenuar parte dessa disparidade.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{figuras/acc_por_time_dot.png}
    \caption{Desempenho do modelo por equipe comparando a acurácia quando o time atua como mandante (círculos) e como visitante (xis). 
    Cada par de marcadores é ligado por um segmento para facilitar a leitura do deslocamento mandante\,–\,visitante. 
    Valores mais à direita indicam maior acurácia, diferenças grandes entre os marcadores sugerem forte assimetria de mando.}
    \label{fig:acc_team_home_away}
    \legend{Fonte: elaboração própria.}
\end{figure}


\subsection{Acurácia ao longo do tempo}
\label{subsec:acc_tempo}

A análise mensal da temporada 2024–2025 mostra acurácia estável entre 65\% e 68\%, com leve aumento em março e estabilização em abril (Figura \ref{fig:acc_mes}). Essa constância sugere que o modelo mantém desempenho consistente, mas também indica certa insensibilidade a dinâmicas sazonais, como desgaste físico, trocas de elenco e variação de intensidade próxima aos \textit{playoffs}.

Três fatores ajudam a interpretar o comportamento observado:
\begin{enumerate}[noitemsep, topsep=0pt]
    \item Estabilização das janelas temporais: no início da temporada há escassez de dados recentes e maior variância no desempenho das equipes, o que reduz a confiabilidade das previsões. A partir de janeiro, as janelas temporais (\textit{Optimal Temporal Windows}) incorporam volume suficiente de jogos e tornam-se mais informativas, o que explica o leve ganho em março.
    \item Densidade de calendário e fadiga: meses com sequências de jogos consecutivos (\textit{back-to-back}) reduzem o desempenho geral e introduzem ruído nos atributos de desempenho médio. O modelo, por não incluir variáveis explícitas de descanso entre partidas, tende a suavizar esse efeito e, portanto, apresenta estabilidade aparente.
    \item Ausência de adaptação intraestacional: embora o modelo respeite a cronologia e o embargo temporal de 24 horas, ele não é continuamente recalibrado ao longo da temporada. Ajustes táticos e transações, como trocas em fevereiro, não são imediatamente incorporados às previsões subsequentes, limitando a captura de microdinâmicas mensais.
\end{enumerate}

A estabilidade observada não deve ser interpretada como falta de capacidade preditiva, mas como indício de que o modelo prioriza consistência temporal em detrimento da sensibilidade contextual.

Para evitar superinterpretação, as acurácias mensais devem ser acompanhadas do número de jogos e de intervalos de confiança binomiais. Essa abordagem assegura comparabilidade e reduz o risco de conclusões baseadas em variações de pequena amostra.

%% plotei esses dois gráficos errados, lembrar de corrigir eh de out-abr
 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figuras/acc_geral.jpeg}
    \caption{Acurácia mensal do modelo no conjunto de teste (temporada 2024–2025). Observa-se estabilidade em torno de 65\%–68\%, com leve elevação em março, possivelmente associada à consolidação das rotações e à redução de variabilidade entre equipes.}
    \label{fig:acc_mes}
    \legend{Fonte: elaboração própria (2025).}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figuras/acc_mes_ic.png} 
    \caption{Evolução da acurácia mensal no conjunto de teste, com faixa sombreada indicando o intervalo de confiança binomial de 95\%. A linha contínua com marcadores representa a acurácia de cada mês e a linha tracejada indica a linha de base (\(\approx 0{,}536\)). Observa-se maior incerteza em meses com amostras menores (faixas mais largas).}
    \label{fig:acc_mensal_ic95}
    \legend{Fonte: elaboração própria.}
\end{figure}


\subsection{Análise de limiar de decisão}
\label{subsec:limiar}
A variação do limiar de decisão permite ajustar precisão e recall conforme objetivo do usuário. Observou-se ponto de equilíbrio adequado em torno de um limiar superior a 0,50. A Tabela \ref{tab:threshold} apresenta um exemplo ilustrativo. 

\begin{table}[H]
\centering
\caption{Exemplo de métricas por limiar de decisão}
\label{tab:threshold}
\footnotesize
\begin{tabular}{lccc}
\hline
Limiar & Acurácia & Precisão & Recall \\
\hline
0,50 & 65,64\% & 0,66 & 0,65 \\
0,56 & 66,30\% & 0,69 & 0,61 \\
0,60 & 66,05\% & 0,71 & 0,58 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\caption{Curva de desempenho por limiar de decisão}
\includegraphics[width=0.75\textwidth]{figuras/threshold_tradeoffs.png}
\caption*{\footnotesize Fonte: elaboração própria.}
\label{fig:threshold_curve}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{figuras/threshold_tradeoffs.png}
\caption{Trade-offs entre métricas por limiar de decisão. As curvas mostram Accuracy, Precision, Recall e F1 em função do limiar; a linha tracejada marca o threshold padrão (0{,}5).}
\legend{Fonte: elaboração própria.}
\label{fig:threshold_curve}
\end{figure}


\section{Análise de ablação}
\label{sec:ablacao}
Para mensurar a contribuição de diferentes grupos de variáveis na performance do modelo, foram comparadas três configurações progressivamente mais simples:

\begin{table}[H]
    \centering
    \caption{Resultados da análise de ablação}
    \label{tab:ablacao}
    \footnotesize
    \begin{tabular}{lccc}
        \toprule
        Configuração & AUC & Acurácia & $\Delta$ vs. completo \\
        \midrule
        Modelo completo & 0,7036 & 65,64\% & --- \\
        Sem atributos de jogadores & 0,6610 & 61,20\% & -4,44 p.p. \\
        Baseline (equipe + calendário) & 0,5890 & 55,12\% & -10,52 p.p. \\
        \bottomrule
    \end{tabular}
    \caption*{\small Nota: p.p. = pontos percentuais. O modelo completo inclui todas as features descritas no Capítulo 3. 
    A versão sem atributos de jogadores remove as agregações de estatísticas individuais. 
    O baseline mantém apenas métricas básicas de equipe e variáveis de calendário.}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figuras/ablation_comparison.png} 
\caption{Comparação entre o modelo sem atributos de jogadores (baseline) e o modelo completo no conjunto de teste. À esquerda, acurácia (\%); à direita, AUC.}
\legend{Fonte: elaboração própria.}
\label{fig:ablacao_barras}
\end{figure}


Os resultados indicam que os atributos derivados de estatísticas individuais dos jogadores contribuem significativamente para o desempenho do modelo, respondendo por aproximadamente 42\% do ganho total de acurácia sobre o baseline (4,44 de 10,52 pontos percentuais). A queda substancial de AUC ao remover estas variáveis (de 0,7036 para 0,6610) sugere que informações no nível do jogador são cruciais para a capacidade discriminativa do modelo.
\section{Explicabilidade das predições}
\label{sec:shap_resultados}
A análise SHAP em teste temporal apontou maior impacto para diferenças de desempenho recente entre mandante e visitante, vantagem de descanso, indicadores de sequência e agregados de jogadores com maior tempo em quadra. A Figura \ref{fig:shap_importance} apresenta as 20 variáveis mais importantes segundo a média de valores absolutos de SHAP.
% --- (1) Importâncias médias por SHAP (Top 20) ---
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figuras/shap.jpeg}
    \caption{Top 20 variáveis mais importantes segundo a média de $|$SHAP$|$ no conjunto de teste. 
    As barras indicam a contribuição média absoluta para deslocar a probabilidade de vitória do mandante.}
    \legend{Fonte: elaboração própria.}
    \label{fig:shap_importance}
\end{figure}


\section{Validação da janela temporal ótima}
\label{sec:otw_resultados}
A avaliação empírica com diferentes comprimentos de janela mostrou melhor desempenho médio entre 8 e 12 jogos, enquanto janelas curtas aumentam ruído e janelas longas diluem a forma recente. A Figura \ref{fig:otw_auc} ilustra o comportamento AUC por tamanho de janela. Esses achados sustentam a heurística dinâmica adotada entre 5 e 20 jogos.



\section{Calibração das Probabilidades}

Após o treinamento do classificador, avaliou-se a qualidade das probabilidades prevendo a confiabilidade por faixas, o \textit{Brier score} e a curva de calibração. Um modelo pode discriminar bem vitórias e derrotas e, ainda assim, apresentar probabilidades desajustadas; por exemplo, atribuir 70\% de chance e observar frequências reais afastadas desse valor.

O procedimento adotado seguiu três passos: (i) medição da confiabilidade por faixas de probabilidade e cálculo do \textit{Brier score}; (ii) verificação de viés sistemático de confiança, tanto para favoritos quanto para azarões; (iii) aplicação de calibração pós-treino quando o viés excedeu um limiar pré-definido. As partições respeitaram a cronologia para evitar uso indevido de informações futuras.

Nos resultados deste trabalho, a calibração isotônica melhorou levemente o \textit{Brier score} no conjunto de teste (0{,}2178 para 0{,}2167), porém reduziu discretamente a AUC (0{,}7143 para 0{,}7123) e piorou o \textit{log loss} (0{,}6258 para 0{,}7051). Assim, as probabilidades calibradas são mais fiéis em termos de frequência observada, mas, para decisões sensíveis a \textit{log loss} e ordenação, o modelo não calibrado apresentou desempenho superior.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figuras/calibration_ece.png}
\caption{Curva de confiabilidade do modelo no conjunto de teste. A linha tracejada indica calibração perfeita; a linha contínua apresenta a fração de vitórias reais por faixa de probabilidade.}
\legend{Fonte: elaboração própria.}
\label{fig:calib_ece}
\end{figure}

\begin{table}[htbp]
\centering
\caption{Métricas antes e depois da calibração no conjunto de teste}
\begin{tabular}{lcc}
\toprule
Métrica & Antes & Depois (isotônica) \\
\midrule
Acurácia          & 0{,}6638 & 0{,}6626 \\
AUC-ROC           & 0{,}7143 & 0{,}7123 \\
\textit{Log loss} & 0{,}6258 & 0{,}7051 \\
\textit{Brier score} & 0{,}2178 & 0{,}2167 \\
\bottomrule
\end{tabular}
\legend{Fonte: elaboração própria.}
\label{tab:calibracao_metricas}
\end{table}


% escolher um jogo dps e printar o shap
\section{Estudo de caso de predição individual}
\label{sec:pred_individual}
Para um confronto prospectivo, o pipeline gera atributos com base apenas nas informações disponíveis até a véspera e retorna a probabilidade prevista de vitória. A Figura \ref{fig:shap_local} pode apresentar a decomposição contribucional da probabilidade para o jogo escolhido.


\section{Discussão dos resultados}
\label{sec:discussao_resultados}

Os resultados obtidos demonstram que o modelo alcançou desempenho competitivo frente à literatura e validaram as principais hipóteses deste estudo. O ganho de 11{,}88 pontos percentuais em acurácia sobre a linha de base confirma a relevância das \textit{features} de jogadores e a adequação da estratégia de validação temporal.

A comparação com estudos anteriores reforça a consistência dos achados. \citeonline{horvat2023} reportam acurácia média em torno de 66\%, enquanto \citeonline{khanmohammadi2024} apresentam AUC entre 0{,}72 e 0{,}82, valores próximos aos observados neste trabalho. Diferenças metodológicas, como composição do conjunto de dados e horizonte temporal, explicam parte da discrepância. 

O desempenho heterogêneo entre equipes também é coerente com a teoria: elencos estáveis, como Oklahoma City Thunder e Utah Jazz, apresentam maior previsibilidade, enquanto times em reconstrução ou com alta rotatividade, como Indiana Pacers e San Antonio Spurs, sofrem queda de precisão. Tais variações reforçam que a estabilidade da rotação e a consistência tática afetam diretamente a capacidade preditiva de modelos baseados em desempenho recente.

A análise de ablação confirmou a importância dos atributos em nível de elenco. A remoção dessas variáveis reduziu a acurácia em 4{,}44 pontos percentuais e o AUC em 0{,}0426, evidenciando que a dimensão individual dos jogadores é determinante para captar o contexto competitivo real. A calibração isotônica, por sua vez, aprimorou a confiança das probabilidades, reduzindo o viés de previsão observado nas primeiras iterações.

Em síntese, o conjunto dos experimentos valida a hipótese central de que a integração de estatísticas de jogadores, janelas temporais adaptativas e validação temporal rigorosa eleva o desempenho preditivo em relação às abordagens simplificadas baseadas apenas em médias de equipe.

% ========================================================================
% CAPÍTULO 5: CONCLUSAO
% ========================================================================
\chapter{Conclusão}
\label{cap:conclusao}

Este trabalho desenvolveu um modelo de \textit{machine learning} para previsão de resultados de jogos da NBA, com uso do classificador CatBoost e uma arquitetura de engenharia de atributos que combina informações contextuais de equipes e estatísticas agregadas de jogadores. O processo de validação adotou partições temporais com embargo de 24 horas, garantindo a integridade causal dos experimentos.

O modelo alcançou acurácia de 65{,}64\% e AUC-ROC de 0{,}7036, superando a linha de base de 53{,}77\%. Esses resultados demonstram ganho estatisticamente consistente e indicam que a modelagem proposta é capaz de ordenar corretamente a maioria dos confrontos, atribuindo maior probabilidade às equipes vencedoras na maior parte dos casos.

Entre as principais contribuições estão: 
\begin{enumerate}[noitemsep, topsep=0pt]
    \item a demonstração da relevância de \textit{features} derivadas de jogadores para aprimorar modelos preditivos de desempenho coletivo; 
    \item a aplicação rigorosa de validação temporal e calibração isotônica, que reduzem viés e aumentam a confiabilidade probabilística; 
    \item e a introdução da heurística de janela temporal adaptativa, ajustando dinamicamente o histórico considerado para cada equipe.
\end{enumerate}

Como limitações, destacam-se a dependência de dados públicos sujeitos a inconsistências e a ausência de variáveis exógenas, como viagens, clima ou indicadores de fadiga fisiológica. Também não foram explorados modelos híbridos com redes neurais temporais ou arquiteturas de atenção, que podem capturar interações mais complexas entre jogadores e partidas.

\subsection*{Trabalhos Futuros}

Por conta de limitações impostas no projeto para poder ser desenvolvido no tempo proposto, e comportamentos da solução durante testes, há algumas sugestões de melhorias e adições que podem ser úteis em trabalhos futuros:
\begin{itemize}
    \item Otimização sistemática das janelas temporais por equipe e por fase da temporada, à luz de \citeonline{horvat2023}.
    \item Enriquecimento de dados com indicadores de disponibilidade e carga de trabalho de jogadores, bem como métricas de força do elenco e \textit{matchups}.
    \item Avaliação do uso controlado de \textit{odds} como variável explicativa, com testes de robustez para evitar sobreajuste a mercado.
    \item Calibração probabilística e ajuste de limiar baseados em função-objetivo prática, incluindo \textit{Brier score} e curvas de ganho.
    \item Estratégias de \textit{ensembling} e modelos hierárquicos que acomodem heterogeneidade entre equipes.
    \item Análise de subgrupos por margem de vitória e contexto, conforme indícios de sensibilidade observados na literatura \citeonline{lunelli2019}.
\end{itemize}


\postextual
\bibliographystyle{abntex2-alf}
\bibliography{tcc/bibliografia}
\end{document}
